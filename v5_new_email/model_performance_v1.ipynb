{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea99ad2-fc19-40de-888b-fb30430cd186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/opt/omniai/work/instance1/jupyter/v5_new_email/Fine-Tuning\")\n",
    "sys.path=list(set(sys.path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c89d56-af93-49a9-92eb-a343b89c1813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment=None\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas(position=0,leave=True)\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import utils\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30d4b29-490f-43d7-8978-f6f56b079497",
   "metadata": {},
   "source": [
    "### Transformer Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a76b43e-3bc1-4a17-a2b5-0a5eaff6898b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"roberta-large\"\n",
    "model_path=os.path.join(\"/opt/omniai/work/instance1/jupyter/\", \"transformers-models\",model_name)\n",
    "config=AutoConfig.from_pretrained(model_path)\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
    "model=AutoModel.from_pretrained(model_path)\n",
    "num_hidden_layers=config.num_hidden_layers\n",
    "num_param=sum([p.nelement() for p in model.parameters()])\n",
    "model_summary=pd.DataFrame({\"model_name\":[model_name],\"maximally allowed token\":[config.max_position_embeddings-2],\\\n",
    "                            \"# of parameters\":[num_param],\"num_hidden_layer\":[num_hidden_layers],\"embedding_size\":config.hidden_size})\n",
    "\n",
    "model_name=\"deberta-v3-large\"\n",
    "model_path=os.path.join(\"/opt/omniai/work/instance1/jupyter/\", \"transformers-models\",model_name)\n",
    "config=AutoConfig.from_pretrained(model_path)\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
    "model=AutoModel.from_pretrained(model_path)\n",
    "num_hidden_layers=config.num_hidden_layers\n",
    "num_param=sum([p.nelement() for p in model.parameters()])\n",
    "tempt=pd.DataFrame({\"model_name\":[model_name],\"maximally allowed token\":[config.max_position_embeddings],\\\n",
    "                            \"# of parameters\":[num_param],\"num_hidden_layer\":[num_hidden_layers],\"embedding_size\":config.hidden_size})\n",
    "model_summary=pd.concat([model_summary,tempt],axis=0,ignore_index=True)\n",
    "\n",
    "# model_name=\"deberta-v2-xlarge\"\n",
    "# model_path=os.path.join(\"/opt/omniai/work/instance1/jupyter/\", \"transformers-models\",model_name)\n",
    "# config=AutoConfig.from_pretrained(model_path)\n",
    "# tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
    "# model=AutoModel.from_pretrained(model_path)\n",
    "# num_hidden_layers=config.num_hidden_layers\n",
    "# num_param=sum([p.nelement() for p in model.parameters()])\n",
    "# tempt=pd.DataFrame({\"model_name\":[model_name],\"maximally allowed token\":[config.max_position_embeddings],\\\n",
    "#                             \"# of parameters\":[num_param],\"num_hidden_layer\":[num_hidden_layers],\"embedding_size\":config.hidden_size})\n",
    "# model_summary=pd.concat([model_summary,tempt],axis=0,ignore_index=True)\n",
    "\n",
    "model_name=\"longformer-base-4096\"\n",
    "model_path=os.path.join(\"/opt/omniai/work/instance1/jupyter/\", \"transformers-models\",model_name)\n",
    "config=AutoConfig.from_pretrained(model_path)\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
    "model=AutoModel.from_pretrained(model_path)\n",
    "num_hidden_layers=config.num_hidden_layers\n",
    "num_param=sum([p.nelement() for p in model.parameters()])\n",
    "tempt=pd.DataFrame({\"model_name\":[model_name],\"maximally allowed token\":[config.max_position_embeddings],\\\n",
    "                            \"# of parameters\":[num_param],\"num_hidden_layer\":[num_hidden_layers],\"embedding_size\":config.hidden_size})\n",
    "model_summary=pd.concat([model_summary,tempt],axis=0,ignore_index=True)\n",
    "\n",
    "model_name=\"longformer-large-4096\"\n",
    "model_path=os.path.join(\"/opt/omniai/work/instance1/jupyter/\", \"transformers-models\",model_name)\n",
    "config=AutoConfig.from_pretrained(model_path)\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
    "model=AutoModel.from_pretrained(model_path)\n",
    "num_hidden_layers=config.num_hidden_layers\n",
    "num_param=sum([p.nelement() for p in model.parameters()])\n",
    "tempt=pd.DataFrame({\"model_name\":[model_name],\"maximally allowed token\":[config.max_position_embeddings],\\\n",
    "                            \"# of parameters\":[num_param],\"num_hidden_layer\":[num_hidden_layers],\"embedding_size\":config.hidden_size})\n",
    "model_summary=pd.concat([model_summary,tempt],axis=0,ignore_index=True)\n",
    "\n",
    "model_name=\"bigbird-roberta-large\"\n",
    "model_path=os.path.join(\"/opt/omniai/work/instance1/jupyter/\", \"transformers-models\",model_name)\n",
    "config=AutoConfig.from_pretrained(model_path)\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
    "model=AutoModel.from_pretrained(model_path)\n",
    "num_hidden_layers=config.num_hidden_layers\n",
    "num_param=sum([p.nelement() for p in model.parameters()])\n",
    "tempt=pd.DataFrame({\"model_name\":[model_name],\"maximally allowed token\":[config.max_position_embeddings],\\\n",
    "                            \"# of parameters\":[num_param],\"num_hidden_layer\":[num_hidden_layers],\"embedding_size\":config.hidden_size})\n",
    "model_summary=pd.concat([model_summary,tempt],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c198c2ec-e37c-45a2-bc72-e750d5ea4f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_summary.style.format({\"maximally allowed token\":\"{:,}\",\"# of parameters\":\"{:,}\",\"embedding_size\":\"{:,}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419904bf-813d-4147-996c-49a2c591386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"deberta-v3-large\"\n",
    "model_path=os.path.join(\"/opt/omniai/work/instance1/jupyter/\", \"transformers-models\",model_name)\n",
    "config=AutoConfig.from_pretrained(model_path)\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
    "model=AutoModel.from_pretrained(model_path)\n",
    "num_hidden_layers=config.num_hidden_layers\n",
    "num_param=sum([p.nelement() for p in model.parameters()])\n",
    "model_summary=pd.DataFrame({\"model_name\":[model_name],\"maximally allowed token\":[config.max_position_embeddings],\\\n",
    "                            \"# of parameters\":[num_param],\"num_hidden_layer\":[num_hidden_layers],\"embedding_size\":config.hidden_size})\n",
    "\n",
    "\n",
    "model_name=\"bigbird-roberta-large\"\n",
    "model_path=os.path.join(\"/opt/omniai/work/instance1/jupyter/\", \"transformers-models\",model_name)\n",
    "config=AutoConfig.from_pretrained(model_path)\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
    "model=AutoModel.from_pretrained(model_path)\n",
    "num_hidden_layers=config.num_hidden_layers\n",
    "num_param=sum([p.nelement() for p in model.parameters()])\n",
    "tempt=pd.DataFrame({\"model_name\":[model_name],\"maximally allowed token\":[config.max_position_embeddings],\\\n",
    "                            \"# of parameters\":[num_param],\"num_hidden_layer\":[num_hidden_layers],\"embedding_size\":config.hidden_size})\n",
    "model_summary=pd.concat([model_summary,tempt],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d09c43b-0de8-4396-800e-5a2a2142cd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_summary.style.format({\"maximally allowed token\":\"{:,}\",\"# of parameters\":\"{:,}\",\"embedding_size\":\"{:,}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5af71a-1388-48b3-99ed-a0e28f50552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_read(df, model_name):\n",
    "    # df=pd.read_csv(os.path.join(output_dir , file_name))\n",
    "    true_y=df[\"True_label\"].values\n",
    "    pred_y=df[\"Predicted_label\"].values\n",
    "    pred_prob=df[\"Predicted_prob\"].values\n",
    "    best_threshold=df['best_threshold'].unique()[0]\n",
    "\n",
    "    # test_output=utils.model_evaluate(true_y.reshape(-1),pred_y)\n",
    "    test_output=utils.model_evaluate(true_y.reshape(-1),pred_prob,best_threshold)\n",
    "    metric=pd.DataFrame()\n",
    "    metric[\"model_type\"]=[f\"{model_name}\"]\n",
    "    metric[\"total complaint #\"]=[test_output[\"total positive\"]]\n",
    "    metric[\"false_positive\"]=[test_output[\"false positive\"]]\n",
    "    metric[\"false_negative\"]=[test_output[\"false_negative\"]]\n",
    "    metric[\"precision\"]=[test_output[\"precision\"]]\n",
    "    metric[\"recall\"]=[test_output[\"recall\"]]\n",
    "    metric[\"f1_score\"]=[test_output[\"f1_score\"]]\n",
    "    metric[\"roc_auc\"]=[test_output[\"AUC\"]]\n",
    "    metric[\"pr_auc\"]=[test_output[\"pr_auc\"]]\n",
    "    return metric\n",
    "\n",
    "def style_format(metrics, type=\"test set\"):\n",
    "    # metrics=metrics[metrics[\"model_type\"].apply(lambda x : x.split(\"-\")[0]==model.split(\"-\")[0])].reset_index(drop=True)\n",
    "    return metrics.style.format({\"total complaint #\":\"{:,}\",\"false_positive\":\"{:,}\",\"false_negative\":\"{:,}\", \"precision\":\"{:.2%}\", \"recall\":\"{:.2%}\", \\\n",
    "                                \"f1_score\":\"{:.2%}\", \"roc_auc\":\"{:.2%}\", \"pr_auc\":\"{:.2%}\"}) \\\n",
    "    .set_caption(f\"Performance Summary for {type} \") \\\n",
    "    .set_table_styles([{\n",
    "        'selector': 'caption',\n",
    "        'props': [\n",
    "            ('color', 'red'),\n",
    "            ('font-size', '15px')\n",
    "        ]\n",
    "    }])\n",
    "\n",
    "def dist_func(df, cols):\n",
    "    tempt1=pd.DataFrame(df[cols].value_counts(dropna=False)).reset_index().rename(columns={'index':cols,cols:'count'})\n",
    "    tempt2=pd.DataFrame(df[cols].value_counts(dropna=False,normalize=True)).reset_index().rename(columns={'index':cols,cols:'percentage'})\n",
    "    tempt3=tempt1.merge(tempt2, on=cols, how=\"inner\")\n",
    "    tempt3=tempt3.loc[:,[cols,'count','percentage']]\n",
    "    return tempt3\n",
    "\n",
    "def style_format_dist(df,title):\n",
    "    return df.style.format({'count':'{:,}','percentage':'{:.2%}'})\\\n",
    "           .set_caption(f\"{title}\")\\\n",
    "           .set_table_styles([{'selector': 'caption','props': [('color', 'red'),('font-size', '12px')]}])\n",
    "\n",
    "def metrics_df_func(output_dir, model_name):\n",
    "    data_name=[x for x in os.listdir(output_dir) if x.split(\".\")[-1]==\"csv\"]\n",
    "    data_name=sorted(data_name)\n",
    "    df=pd.read_csv(os.path.join(output_dir , data_name[0]))\n",
    "    metrics=metrics_read(df,model_name)\n",
    "    N=data_name[0].split(\"_\")[1].split(\".\")[0]\n",
    "    metrics.insert(0,\"Recall in Val\",[f\"recall>={N}0%\"])\n",
    "    \n",
    "    for i in range(1,len(data_name)):\n",
    "        df=pd.read_csv(os.path.join(output_dir , data_name[i]))\n",
    "        tempt=metrics_read(df,model_name)\n",
    "        N=data_name[i].split(\"_\")[1].split(\".\")[0]\n",
    "        tempt.insert(0,\"Recall in Val\",[f\"recall>={N}%\"])\n",
    "        metrics=pd.concat([metrics,tempt],axis=0,ignore_index=True)\n",
    "        \n",
    "    return metrics\n",
    "\n",
    "def metrics_df(output_dir, model_name):\n",
    "    data_name=[x for x in os.listdir(output_dir) if x.split(\".\")[-1]==\"csv\"]\n",
    "    data_name=sorted(data_name)\n",
    "    df=pd.read_csv(os.path.join(output_dir , data_name[0]))\n",
    "    metrics=metrics_read(df,model_name)\n",
    "    for i in range(1,len(data_name)):\n",
    "        df=pd.read_csv(os.path.join(output_dir , data_name[i]))\n",
    "        metrics=pd.concat([metrics,metrics_read(df,model_name)],axis=0,ignore_index=True)\n",
    "        \n",
    "    metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cdcc35-00ee-44bd-b6f9-4dc6006090f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_rate_eval(logit,label,topk):\n",
    "    DF=pd.DataFrame(columns=[\"pred_score\",\"actual_label\"])\n",
    "    DF[\"pred_score\"]=logit\n",
    "    DF[\"actual_label\"]=label\n",
    "    DF.sort_values(by=\"pred_score\", ascending=False, inplace=True)\n",
    "    response_rate={}\n",
    "    for p in topk:\n",
    "        N=math.ceil(int(DF.shape[0]*p))\n",
    "        DF2=DF.nlargest(N,\"pred_score\",keep=\"first\")\n",
    "        response_rate[str(int(p*100))+\"%\"]=DF2.actual_label.sum()/DF2.shape[0]\n",
    "    return response_rate\n",
    "\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "def bar_plot(data, colors=None, total_width=0.8, single_width=1, legend=True,title=None,subtitle=None,axis_truncation=0.5):\n",
    "    \"\"\"Draws a bar plot with multiple bars per data point.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ax : matplotlib.pyplot.axis\n",
    "        The axis we want to draw our plot on.\n",
    "\n",
    "    data: dictionary\n",
    "        A dictionary containing the data we want to plot. Keys are the names of the\n",
    "        data, the items is a list of the values.\n",
    "\n",
    "        Example:\n",
    "        data = {\n",
    "            \"x\":[1,2,3],\n",
    "            \"y\":[1,2,3],\n",
    "            \"z\":[1,2,3],\n",
    "        }\n",
    "\n",
    "    colors : array-like, optional\n",
    "        A list of colors which are used for the bars. If None, the colors\n",
    "        will be the standard matplotlib color cyle. (default: None)\n",
    "\n",
    "    total_width : float, optional, default: 0.8\n",
    "        The width of a bar group. 0.8 means that 80% of the x-axis is covered\n",
    "        by bars and 20% will be spaces between the bars.\n",
    "\n",
    "    single_width: float, optional, default: 1\n",
    "        The relative width of a single bar within a group. 1 means the bars\n",
    "        will touch eachother within a group, values less than 1 will make\n",
    "        these bars thinner.\n",
    "\n",
    "    legend: bool, optional, default: True\n",
    "        If this is set to true, a legend will be added to the axis.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if colors where provided, otherwhise use the default color cycle\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize =(15, 8))\n",
    "    \n",
    "    if colors is None:\n",
    "        colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    \n",
    "    # Number of bars per group\n",
    "    n_bars = len(data)\n",
    "\n",
    "    # The width of a single bar\n",
    "    bar_width = total_width / n_bars\n",
    "\n",
    "    # List containing handles for the drawn bars, used for the legend\n",
    "    bars = []\n",
    "\n",
    "    # Iterate over all data\n",
    "    for i, (name, values) in enumerate(data.items()):\n",
    "        # The offset in x direction of that bar\n",
    "        x_offset = (i - n_bars / 2) * bar_width + bar_width / 2\n",
    "\n",
    "        # Draw a bar for every value of that type\n",
    "        for x, y in enumerate(values.values()):\n",
    "            bar = ax.bar(x + x_offset, y, width=bar_width * single_width, color=colors[i % len(colors)])\n",
    "\n",
    "        # Add a handle to the last drawn bar, which we'll need for the legend\n",
    "        bars.append(bar[0])\n",
    "\n",
    "    # Draw legend if we need\n",
    "    if legend:\n",
    "        ax.legend(bars, data.keys())\n",
    "    \n",
    "    ax.set_ylabel('Accuracy',fontsize=15)\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(lambda y,_: \"{:.0%}\".format(y)))\n",
    "    ind=np.arange(len(data[list(data.keys())[0]]))\n",
    "    ax.set_xticks(ind)\n",
    "    ax.set_xticklabels( ('top 1% score', 'top 2% score', 'top 5% score','top 10% score') )\n",
    "    ax.set_title(f\"Top Predicted Score  \",fontsize=15)\n",
    "    \n",
    "    #     plt.xlim([0, 1])\n",
    "    # plt.ylim([axis_truncation, 1])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1b37e6-7a43-4855-8aa4-612fb4c44e94",
   "metadata": {},
   "source": [
    "#### TFIDF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec9385b-f0e9-4410-82f3-444b44b6041e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### treat feedback as complaint in training and validation dataset\n",
    "model_name=\"xgboost\"\n",
    "test_date=\"04_23\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/TFIDF/tfidf_model/{test_date}/{model_name}/\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "metrics.sort_values(\"recall\",inplace=True)\n",
    "metrics=metrics.reset_index(drop=True)\n",
    "metrics.loc[0,\"Recall in Val\"]=\"default\"\n",
    "\n",
    "style_format(metrics,  type=f\"{model_name} model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f12de95-589d-4253-8ded-7a1c24c134f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ground true complaint in training and validation dataset\n",
    "model_name=\"xgboost\"\n",
    "test_date=\"04_23\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/TFIDF/tfidf_model_v0/{test_date}/{model_name}/\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "metrics.sort_values(\"recall\",inplace=True)\n",
    "metrics=metrics.reset_index(drop=True)\n",
    "metrics.loc[0,\"Recall in Val\"]=\"default\"\n",
    "\n",
    "style_format(metrics,  type=f\"{model_name} model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436b3cc6-1e2d-4a72-a78e-76300b3002af",
   "metadata": {},
   "outputs": [],
   "source": [
    "### treat feedback as complaint in training and validation dataset\n",
    "model_name=\"xgboost\"\n",
    "test_date=\"05_23\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/TFIDF/tfidf_model/{test_date}/{model_name}/\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "metrics.sort_values(\"recall\",inplace=True)\n",
    "metrics=metrics.reset_index(drop=True)\n",
    "metrics.loc[0,\"Recall in Val\"]=\"default\"\n",
    "\n",
    "style_format(metrics,  type=f\"{model_name} model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94487fa-d64f-4eb5-bb87-7d6658f2dc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ground true complaint in training and validation dataset\n",
    "model_name=\"xgboost\"\n",
    "test_date=\"05_23\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/TFIDF/tfidf_model_v0/{test_date}/{model_name}/\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "metrics.sort_values(\"recall\",inplace=True)\n",
    "metrics=metrics.reset_index(drop=True)\n",
    "metrics.loc[0,\"Recall in Val\"]=\"default\"\n",
    "\n",
    "style_format(metrics,  type=f\"{model_name} model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6fc9e5-9891-4d76-85fe-9af10ca9c22e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8e5515-aa0b-4ede-921a-32416df3939e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba97522-fc02-41fb-bd50-cbc55bf36764",
   "metadata": {},
   "outputs": [],
   "source": [
    "### treat feedback as complaint in training and validation dataset\n",
    "model_name=\"lightgbm\"\n",
    "test_date=\"04_23\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/TFIDF/tfidf_model/{test_date}/{model_name}/\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "metrics.sort_values(\"recall\",inplace=True)\n",
    "metrics=metrics.reset_index(drop=True)\n",
    "metrics.loc[0,\"Recall in Val\"]=\"default\"\n",
    "\n",
    "style_format(metrics,  type=f\"{model_name} model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fc5865-2037-4366-8945-e0ca7dcbf653",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ground true complaint in training and validation dataset\n",
    "model_name=\"lightgbm\"\n",
    "test_date=\"04_23\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/TFIDF/tfidf_model_v0/{test_date}/{model_name}/\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "metrics.sort_values(\"recall\",inplace=True)\n",
    "metrics=metrics.reset_index(drop=True)\n",
    "metrics.loc[0,\"Recall in Val\"]=\"default\"\n",
    "\n",
    "style_format(metrics,  type=f\"{model_name} model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aca39ad-d384-4dbf-9c99-fc48e5997c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "### treat feedback as complaint in training and validation dataset\n",
    "model_name=\"lightgbm\"\n",
    "test_date=\"05_23\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/TFIDF/tfidf_model/{test_date}/{model_name}/\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "metrics.sort_values(\"recall\",inplace=True)\n",
    "metrics=metrics.reset_index(drop=True)\n",
    "metrics.loc[0,\"Recall in Val\"]=\"default\"\n",
    "\n",
    "style_format(metrics,  type=f\"{model_name} model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1496ea-e891-4eef-ab1c-6d3e12d5ce0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ground true complaint in training and validation dataset\n",
    "model_name=\"lightgbm\"\n",
    "test_date=\"05_23\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/TFIDF/tfidf_model_v0/{test_date}/{model_name}/\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "metrics.sort_values(\"recall\",inplace=True)\n",
    "metrics=metrics.reset_index(drop=True)\n",
    "metrics.loc[0,\"Recall in Val\"]=\"default\"\n",
    "\n",
    "style_format(metrics,  type=f\"{model_name} model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5432175e-46a8-45f9-a24b-ef935fa4f8e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533aa775-60b6-4ff8-a10a-20a276014d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### treat feedback as complaint in training and validation dataset\n",
    "model_name=\"randomforest\"\n",
    "test_date=\"04_23\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/TFIDF/tfidf_model/{test_date}/{model_name}/\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "metrics.sort_values(\"recall\",inplace=True)\n",
    "metrics=metrics.reset_index(drop=True)\n",
    "metrics.loc[0,\"Recall in Val\"]=\"default\"\n",
    "\n",
    "style_format(metrics,  type=f\"{model_name} model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9faf1c-d0d6-42fe-90fd-5be1626ee01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ground true complaint in training and validation dataset\n",
    "model_name=\"randomforest\"\n",
    "test_date=\"04_23\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/TFIDF/tfidf_model_v0/{test_date}/{model_name}/\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "metrics.sort_values(\"recall\",inplace=True)\n",
    "metrics=metrics.reset_index(drop=True)\n",
    "metrics.loc[0,\"Recall in Val\"]=\"default\"\n",
    "\n",
    "style_format(metrics,  type=f\"{model_name} model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cb9709-8725-459f-8c42-7fa5622d703d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### treat feedback as complaint in training and validation dataset\n",
    "model_name=\"randomforest\"\n",
    "test_date=\"05_23\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/TFIDF/tfidf_model/{test_date}/{model_name}/\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "metrics.sort_values(\"recall\",inplace=True)\n",
    "metrics=metrics.reset_index(drop=True)\n",
    "metrics.loc[0,\"Recall in Val\"]=\"default\"\n",
    "\n",
    "style_format(metrics,  type=f\"{model_name} model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98bdd67-2de2-453e-b842-200724e067b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ground true complaint in training and validation dataset\n",
    "model_name=\"randomforest\"\n",
    "test_date=\"05_23\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/TFIDF/tfidf_model_v0/{test_date}/{model_name}/\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "metrics.sort_values(\"recall\",inplace=True)\n",
    "metrics=metrics.reset_index(drop=True)\n",
    "metrics.loc[0,\"Recall in Val\"]=\"default\"\n",
    "\n",
    "style_format(metrics,  type=f\"{model_name} model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ac0609-fe1a-4ce9-bb94-c28a9991e543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e331b8-6b8c-4ba9-b75d-a235706b2db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### treat feedback as complaint in training and validation dataset\n",
    "model_name=\"catboost\"\n",
    "test_date=\"05_23\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/TFIDF/tfidf_model/{test_date}/{model_name}/\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "metrics.sort_values(\"recall\",inplace=True)\n",
    "metrics=metrics.reset_index(drop=True)\n",
    "metrics.loc[0,\"Recall in Val\"]=\"default\"\n",
    "\n",
    "style_format(metrics,  type=f\"{model_name} model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559501ef-b3c9-437e-91a9-50da724a03cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ground true complaint in training and validation dataset\n",
    "model_name=\"catboost\"\n",
    "test_date=\"05_23\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/TFIDF/tfidf_model_v0/{test_date}/{model_name}/\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "metrics.sort_values(\"recall\",inplace=True)\n",
    "metrics=metrics.reset_index(drop=True)\n",
    "metrics.loc[0,\"Recall in Val\"]=\"default\"\n",
    "\n",
    "style_format(metrics,  type=f\"{model_name} model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f95b0f-6208-4cd6-9937-2bab36719752",
   "metadata": {},
   "source": [
    "#### precision recall curve for TFIDF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f2f0c9-4947-4ea7-a294-ae7f12328850",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_date=\"04_23\"\n",
    "\n",
    "precision=[]\n",
    "recall=[]\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/TFIDF/tfidf_model/{test_date}/xgboost/\"\n",
    "df=metrics_df(output_dir, \"xgboost\")\n",
    "df.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "df=df[df.recall>0.9]\n",
    "df.sort_values(\"recall\",inplace=True)\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/TFIDF/tfidf_model/{test_date}/lightgbm/\"\n",
    "df=metrics_df(output_dir, \"lightgbm\")\n",
    "df.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "df=df[df.recall>0.9]\n",
    "df.sort_values(\"recall\",inplace=True)\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/TFIDF/tfidf_model/{test_date}/randomforest/\"\n",
    "df=metrics_df(output_dir, \"random-forest\")\n",
    "df.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "df=df[df.recall>0.9]\n",
    "df.sort_values(\"recall\",inplace=True)\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "# output_dir=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/TFIDF/tfidf_model/{test_date}/catboost/\"\n",
    "# df=metrics_df(output_dir, \"catboost\")\n",
    "# df.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "# df=df[df.recall>0.9]\n",
    "# df.sort_values(\"recall\",inplace=True)\n",
    "# precision.append(df[\"precision\"].tolist())\n",
    "# recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "# Define precision and recall values for each model\n",
    "models = ['TFIDF+xgboost','TFIDF+lightgbm','TFIDF+random-forest']\n",
    "\n",
    "markers = ['o', 's', 'D']\n",
    "colors = ['blue', 'green', 'orange']\n",
    "\n",
    "# Plot precision and recall\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Iterate over models\n",
    "for i in range(len(models)):\n",
    "    plt.plot(recall[i], precision[i], marker=markers[i],  color=colors[i], label=models[i], linewidth=3, linestyle=\":\", markersize=8)\n",
    "\n",
    "plt.xlabel('Recall', fontsize=14)\n",
    "plt.ylabel('Precision', fontsize=14)\n",
    "plt.title('Precision-Recall Curve \\n(test_set=04/2023)', fontsize=16)\n",
    "plt.grid(True)\n",
    "\n",
    "# Format axis values as percentages\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(mtick.MultipleLocator(base=0.01))\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=0))\n",
    "ax.yaxis.set_major_locator(mtick.MultipleLocator(base=0.001))\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=2))\n",
    "\n",
    "plt.ylim(0.006,0.01)\n",
    "plt.xlim(0.90,1.01)\n",
    "\n",
    "# # Add horizontal line for benchmark model\n",
    "# benchmark_precision=0.0053\n",
    "# plt.axhline(y=benchmark_precision, color=(0.8,0.7,0.5),linestyle='--', linewidth=3)\n",
    "\n",
    "# Set the legend\n",
    "plt.legend()\n",
    "# plt.legend(models+[\"Lexican Search\"],bbox_to_anchor=(1,0.5), fontsize=14)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0d49fb-dc47-4b6f-975b-a2bccddb8383",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_date=\"05_23\"\n",
    "\n",
    "precision=[]\n",
    "recall=[]\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/TFIDF/tfidf_model/{test_date}/xgboost/\"\n",
    "df=metrics_df(output_dir, \"xgboost\")\n",
    "df.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "df=df[df.recall>0.9]\n",
    "df.sort_values(\"recall\",inplace=True)\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/TFIDF/tfidf_model/{test_date}/lightgbm/\"\n",
    "df=metrics_df(output_dir, \"lightgbm\")\n",
    "df.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "df=df[df.recall>0.9]\n",
    "df.sort_values(\"recall\",inplace=True)\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/TFIDF/tfidf_model/{test_date}/randomforest/\"\n",
    "df=metrics_df(output_dir, \"random-forest\")\n",
    "df.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "df=df[df.recall>0.9]\n",
    "df.sort_values(\"recall\",inplace=True)\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "# output_dir=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/TFIDF/tfidf_model/{test_date}/catboost/\"\n",
    "# df=metrics_df(output_dir, \"catboost\")\n",
    "# df.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "# df=df[df.recall>0.9]\n",
    "# df.sort_values(\"recall\",inplace=True)\n",
    "# precision.append(df[\"precision\"].tolist())\n",
    "# recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "# Define precision and recall values for each model\n",
    "models = ['TFIDF+xgboost','TFIDF+lightgbm','TFIDF+random-forest']\n",
    "\n",
    "markers = ['o', 's', 'D']\n",
    "colors = ['blue', 'green', 'orange']\n",
    "\n",
    "# Plot precision and recall\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Iterate over models\n",
    "for i in range(len(models)):\n",
    "    plt.plot(recall[i], precision[i], marker=markers[i],  color=colors[i], label=models[i], linewidth=3, linestyle=\":\", markersize=8)\n",
    "\n",
    "plt.xlabel('Recall', fontsize=14)\n",
    "plt.ylabel('Precision', fontsize=14)\n",
    "plt.title('Precision-Recall Curve \\n(test_set=05/2023)', fontsize=16)\n",
    "plt.grid(True)\n",
    "\n",
    "# Format axis values as percentages\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(mtick.MultipleLocator(base=0.01))\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=0))\n",
    "ax.yaxis.set_major_locator(mtick.MultipleLocator(base=0.001))\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=2))\n",
    "\n",
    "plt.ylim(0.008,0.014)\n",
    "plt.xlim(0.90,1.01)\n",
    "\n",
    "# # Add horizontal line for benchmark model\n",
    "# benchmark_precision=0.0053\n",
    "# plt.axhline(y=benchmark_precision, color=(0.8,0.7,0.5),linestyle='--', linewidth=3)\n",
    "\n",
    "# Set the legend\n",
    "plt.legend()\n",
    "# plt.legend(models+[\"Lexican Search\"],bbox_to_anchor=(1,0.5), fontsize=14)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d89022-9cbe-4796-82c5-6cd26fde2b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_date=\"05_23\"\n",
    "model_name=\"lightgbm\"\n",
    "precision=[]\n",
    "recall=[]\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/TFIDF/tfidf_model_v0/{test_date}/{model_name}/\"\n",
    "df=metrics_df(output_dir, \"lightgbm\")\n",
    "df.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "df=df[df.recall>0.9]\n",
    "df.sort_values(\"recall\",inplace=True)\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/TFIDF/tfidf_model/{test_date}/{model_name}/\"\n",
    "df=metrics_df(output_dir, \"random-forest\")\n",
    "df.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "df=df[df.recall>0.9]\n",
    "df.sort_values(\"recall\",inplace=True)\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "# Define precision and recall values for each model\n",
    "models = ['ground true complaint','treat feedback as complaint']\n",
    "\n",
    "markers = ['o', 's']\n",
    "colors = ['blue', 'green']\n",
    "\n",
    "# Plot precision and recall\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Iterate over models\n",
    "for i in range(len(models)):\n",
    "    plt.plot(recall[i], precision[i], marker=markers[i],  color=colors[i], label=models[i], linewidth=3, linestyle=\":\", markersize=8)\n",
    "\n",
    "plt.xlabel('Recall', fontsize=14)\n",
    "plt.ylabel('Precision', fontsize=14)\n",
    "plt.title('Precision-Recall Curve -- lightgbm \\n(test_set=05/2023)', fontsize=16)\n",
    "plt.grid(True)\n",
    "\n",
    "# Format axis values as percentages\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(mtick.MultipleLocator(base=0.01))\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=0))\n",
    "ax.yaxis.set_major_locator(mtick.MultipleLocator(base=0.001))\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=2))\n",
    "\n",
    "# plt.ylim(0.008,0.014)\n",
    "# plt.xlim(0.90,1.01)\n",
    "\n",
    "# # Add horizontal line for benchmark model\n",
    "# benchmark_precision=0.0053\n",
    "# plt.axhline(y=benchmark_precision, color=(0.8,0.7,0.5),linestyle='--', linewidth=3)\n",
    "\n",
    "# Set the legend\n",
    "plt.legend()\n",
    "# plt.legend(models+[\"Lexican Search\"],bbox_to_anchor=(1,0.5), fontsize=14)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25253ddc-80ee-4d8b-8e4f-92cc9f7cd53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_date=\"05_23\"\n",
    "model_name=\"xgboost\"\n",
    "precision=[]\n",
    "recall=[]\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/TFIDF/tfidf_model_v0/{test_date}/{model_name}/\"\n",
    "df=metrics_df(output_dir, \"lightgbm\")\n",
    "df.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "df=df[df.recall>0.9]\n",
    "df.sort_values(\"recall\",inplace=True)\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/TFIDF/tfidf_model/{test_date}/{model_name}/\"\n",
    "df=metrics_df(output_dir, \"random-forest\")\n",
    "df.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "df=df[df.recall>0.9]\n",
    "df.sort_values(\"recall\",inplace=True)\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "# Define precision and recall values for each model\n",
    "models = ['ground true complaint','treat feedback as complaint']\n",
    "\n",
    "markers = ['o', 's']\n",
    "colors = ['blue', 'green']\n",
    "\n",
    "# Plot precision and recall\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Iterate over models\n",
    "for i in range(len(models)):\n",
    "    plt.plot(recall[i], precision[i], marker=markers[i],  color=colors[i], label=models[i], linewidth=3, linestyle=\":\", markersize=8)\n",
    "\n",
    "plt.xlabel('Recall', fontsize=14)\n",
    "plt.ylabel('Precision', fontsize=14)\n",
    "plt.title('Precision-Recall Curve -- xgboost \\n(test_set=05/2023)', fontsize=16)\n",
    "plt.grid(True)\n",
    "\n",
    "# Format axis values as percentages\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(mtick.MultipleLocator(base=0.01))\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=0))\n",
    "ax.yaxis.set_major_locator(mtick.MultipleLocator(base=0.001))\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=2))\n",
    "\n",
    "# plt.ylim(0.008,0.014)\n",
    "# plt.xlim(0.90,1.01)\n",
    "\n",
    "# # Add horizontal line for benchmark model\n",
    "# benchmark_precision=0.0053\n",
    "# plt.axhline(y=benchmark_precision, color=(0.8,0.7,0.5),linestyle='--', linewidth=3)\n",
    "\n",
    "# Set the legend\n",
    "plt.legend()\n",
    "# plt.legend(models+[\"Lexican Search\"],bbox_to_anchor=(1,0.5), fontsize=14)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47658eb-f13f-4dc5-bf4d-075ed178574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_date=\"05_23\"\n",
    "model_name=\"randomforest\"\n",
    "precision=[]\n",
    "recall=[]\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/TFIDF/tfidf_model_v0/{test_date}/{model_name}/\"\n",
    "df=metrics_df(output_dir, \"random-forest\")\n",
    "df.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "df=df[df.recall>0.9]\n",
    "df.sort_values(\"recall\",inplace=True)\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/TFIDF/tfidf_model/{test_date}/{model_name}/\"\n",
    "df=metrics_df(output_dir, \"random-forest\")\n",
    "df.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "df=df[df.recall>0.9]\n",
    "df.sort_values(\"recall\",inplace=True)\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "# Define precision and recall values for each model\n",
    "models = ['ground true complaint','treat feedback as complaint']\n",
    "\n",
    "markers = ['o', 's']\n",
    "colors = ['blue', 'green']\n",
    "\n",
    "# Plot precision and recall\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Iterate over models\n",
    "for i in range(len(models)):\n",
    "    plt.plot(recall[i], precision[i], marker=markers[i],  color=colors[i], label=models[i], linewidth=3, linestyle=\":\", markersize=8)\n",
    "\n",
    "plt.xlabel('Recall', fontsize=14)\n",
    "plt.ylabel('Precision', fontsize=14)\n",
    "plt.title('Precision-Recall Curve -- random-forest \\n(test_set=05/2023)', fontsize=16)\n",
    "plt.grid(True)\n",
    "\n",
    "# Format axis values as percentages\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(mtick.MultipleLocator(base=0.01))\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=0))\n",
    "ax.yaxis.set_major_locator(mtick.MultipleLocator(base=0.001))\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=2))\n",
    "\n",
    "# plt.ylim(0.008,0.014)\n",
    "# plt.xlim(0.90,1.01)\n",
    "\n",
    "# # Add horizontal line for benchmark model\n",
    "# benchmark_precision=0.0053\n",
    "# plt.axhline(y=benchmark_precision, color=(0.8,0.7,0.5),linestyle='--', linewidth=3)\n",
    "\n",
    "# Set the legend\n",
    "plt.legend()\n",
    "# plt.legend(models+[\"Lexican Search\"],bbox_to_anchor=(1,0.5), fontsize=14)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e6f07e-440c-42fe-b94f-7b83a636b15b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6950d0b7-a28b-4f19-94df-51845ba70936",
   "metadata": {},
   "source": [
    "### roberta-large model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4bb21c-9719-42d5-80b9-16734904f2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"roberta_large\"\n",
    "test_date=\"04_23\"\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "model_name=\"bigbird_roberta_large\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "style_format(metrics,  type=\"roberta_large model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f94724-219e-42f6-929e-dc276e5d2e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"roberta_large_customized\"\n",
    "test_date=\"04_23\"\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "model_name=\"bigbird_roberta_large\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "style_format(metrics,  type=\"customized roberta_large model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e71f23-bed8-4693-85c8-a7f1f12feee2",
   "metadata": {},
   "source": [
    "#### deberta-v3-large model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befccd8e-3136-4643-bdde-0ae92476a46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"deberta_v3_large\"\n",
    "test_date=\"04_23\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "model_name=\"deberta-v3-large\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "style_format(metrics,  type=\"deberta-v3-large model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dddc8d-9c4d-43de-ac6c-b9c8d47708d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aefcfed-3a66-4af0-839b-230357a415c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"deberta_v3_large\"\n",
    "test_date=\"04_23\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "df=pd.read_csv(os.path.join(output_dir, \"predictions_96.csv\"))\n",
    "false_positive=df[(df.True_label==0) & (df.Predicted_label==1)]\n",
    "false_negative=df[(df.True_label==1) & (df.Predicted_label==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d0c08e-d7d1-4f57-9515-2e3772031760",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_length_v2\"]=df[\"text_length\"].apply(lambda x: \"len<=512\" if x<=512 else \"len>512\")\n",
    "style_format_dist(dist_func(df, \"text_length_v2\"),title=\"text length in test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a6bac7-d190-462e-ae15-94fe99f5327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment=None\n",
    "false_positive[\"text_length\"]=false_positive[\"text_length\"].apply(lambda x: \"len<=512\" if x<=512 else \"len>512\")\n",
    "style_format_dist(dist_func(false_positive, \"text_length\"),title=\"text length in false positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed39a8be-9238-4fc0-90d9-3ea02302cd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negative[\"text_length\"]=false_negative[\"text_length\"].apply(lambda x: \"len<=512\" if x<=512 else \"len>512\")\n",
    "style_format_dist(dist_func(false_negative, \"text_length\"),title=\"text length in false negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5b8665-9750-4d0a-a55f-399181aa541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"deberta_v3_large\"\n",
    "test_date=\"04_23\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "df=pd.read_csv(os.path.join(output_dir, \"predictions_96.csv\"))\n",
    "deberta_v3_true, deberta_v3_pred=df[\"True_label\"].tolist(), df[\"Predicted_label\"].tolist()\n",
    "\n",
    "from sklearn import metrics\n",
    "confusion_matrix = metrics.confusion_matrix(deberta_v3_true, deberta_v3_pred)\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
    "\n",
    "cm_display.plot(values_format=',')\n",
    "plt.title(\"deberta-v3-large Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ca967b-4fb4-4c01-870d-e1787ec44bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir=\"/opt/omniai/work/instance1/jupyter/v2_new_email/Fine-Tuning/results/deberta_v3_large\"\n",
    "df=pd.read_csv(os.path.join(output_dir, \"predictions_97.csv\"))\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceda8c17-3e0b-4bb2-9fd5-9937c81beb4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8daf88d-80e5-4f49-8398-c1136a4e238a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cf07c3d-6c80-4fb4-b06f-f2969bc46abf",
   "metadata": {},
   "source": [
    "#### deberta-v2-xlarge Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80530eb9-b845-4c70-a512-fd09a18bab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"deberta_v2_xlarge\"\n",
    "test_date=\"04_23\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "model_name=\"deberta-v2-xlarge\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "style_format(metrics,  type=\"deberta-v2-xlarge model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216a56bc-8218-46b4-9804-8eeb91bf16b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3697dd8-5175-4a4f-85aa-ea0484345082",
   "metadata": {},
   "source": [
    "#### longformer-base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188d99fc-5e86-4f93-8a83-be55d83681fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"longformer_base_4096\"\n",
    "test_date=\"04_23\"\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "model_name=\"bigbird_roberta_large\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "style_format(metrics,  type=\"longformer_base model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b40423a-2187-4540-9f77-273034be7d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"longformer_base_4096_customized\"\n",
    "test_date=\"04_23\"\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "model_name=\"bigbird_roberta_large\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "style_format(metrics,  type=\"customized longformer_base model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72244fe-08a3-4324-960f-1376f64bd709",
   "metadata": {},
   "source": [
    "#### longformer-large model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b512f3fd-ee2f-414e-9282-3dd85a2dc9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"longformer_large_4096\"\n",
    "test_date=\"04_23\"\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "model_name=\"bigbird_roberta_large\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "style_format(metrics,  type=\"longformer_large model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72ef27b-8ec5-4fb6-8ac0-1a010b971f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"longformer_large_4096_customized\"\n",
    "test_date=\"04_23\"\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "model_name=\"bigbird_roberta_large\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "style_format(metrics,  type=\"customized longformer_large model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a0f942-c79f-4f67-aaf7-519352d48152",
   "metadata": {},
   "source": [
    "#### Bigbird-Roberta-Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd728410-23e6-421e-b182-796a941da6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"bigbird_roberta_large\"\n",
    "test_date=\"04_23\"\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "model_name=\"bigbird_roberta_large\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "style_format(metrics,  type=f\"{model_name} model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27d4a53-8ff6-496d-82b9-48c480fcba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"bigbird_roberta_large_customized\"\n",
    "test_date=\"04_23\"\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "model_name=\"bigbird_roberta_large\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "style_format(metrics,  type=f\"{model_name} model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0742d0-0f3c-489e-80f8-b2f84063ab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"bigbird_roberta_large_customized\"\n",
    "test_date=\"04_23\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "df=pd.read_csv(os.path.join(output_dir, \"predictions_92.csv\"))\n",
    "false_positive=df[(df.True_label==0) & (df.Predicted_label==1)]\n",
    "false_negative=df[(df.True_label==1) & (df.Predicted_label==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc61940-7009-4e79-b20c-dc734b5d09e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_length_v2\"]=df[\"text_length\"].apply(lambda x: \"len<=512\" if x<=512 else \"len>512\")\n",
    "style_format_dist(dist_func(df, \"text_length_v2\"),title=\"text length in test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc60419-6838-4091-9fb5-9644ad2e88a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment=None\n",
    "false_positive[\"text_length\"]=false_positive[\"text_length\"].apply(lambda x: \"len<=512\" if x<=512 else \"len>512\")\n",
    "style_format_dist(dist_func(false_positive, \"text_length\"),title=\"text length in false positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e872783b-2294-4b1c-940b-cba440fa3f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"bigbird_roberta_large_customized\"\n",
    "test_date=\"04_23\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "df=pd.read_csv(os.path.join(output_dir, \"predictions_92.csv\"))\n",
    "bigbird_true, bigbird_pred=df[\"True_label\"].tolist(), df[\"Predicted_label\"].tolist()\n",
    "\n",
    "from sklearn import metrics\n",
    "confusion_matrix = metrics.confusion_matrix(bigbird_true, bigbird_pred)\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
    "\n",
    "cm_display.plot(values_format=',')\n",
    "plt.title(\"bigbird Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05c8f8d-90da-49b6-9828-f3aedccd7b02",
   "metadata": {},
   "source": [
    "#### precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fb4e6d-c3a2-4fda-b4b9-327b6d1a272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_date=\"04_23\"\n",
    "\n",
    "precision=[]\n",
    "recall=[]\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/TFIDF/results/{test_date}/xgboost/\"\n",
    "df=metrics_df(output_dir, \"xgboost\")\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/TFIDF/results/{test_date}/lightgbm/\"\n",
    "df=metrics_df(output_dir, \"lightgbm\")\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/TFIDF/results/{test_date}/randomforest/\"\n",
    "df=metrics_df(output_dir, \"random-forest\")\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/roberta_large_customized\"\n",
    "df=metrics_df(output_dir, \"roberta-large\")\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/deberta_v3_large\"\n",
    "df=metrics_df(output_dir, \"deberta-v3-large\")\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "# output_dir=f\"/opt/omniai/work/instance1/jupyter/v3_new_email/Fine-Tuning/results/deberta_v2_xlarge\"\n",
    "# df=metrics_df(output_dir, \"deberta-v2-xlarge\")\n",
    "# precision.append(df[\"precision\"].tolist())\n",
    "# recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/longformer_base_4096_customized\"\n",
    "df=metrics_df(output_dir, \"longformer_base\")\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/longformer_large_4096_customized\"\n",
    "df=metrics_df(output_dir, \"longformer_large\")\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/bigbird_roberta_large_customized\"\n",
    "df=metrics_df(output_dir, \"bigbird_large\")\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17a0684-6c32-41eb-bad8-5814924ed18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "# Define precision and recall values for each model\n",
    "models = ['TFIDF+xgboost','TFIDF+lightgbm','TFIDF+random-forest','roberta-large','deberta-v3-large','longformer-base', 'longformer-large','bigbird_large']\n",
    "\n",
    "markers = ['o', 's', 'D', 'x', '*', '<', 'p', '^']\n",
    "colors = ['blue', 'green', 'orange', 'red', 'brown','lawngreen', 'purple','black']\n",
    "\n",
    "# Plot precision and recall\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Iterate over models\n",
    "for i in range(len(models)):\n",
    "    plt.plot(recall[i], precision[i], marker=markers[i],  color=colors[i], label=models[i], linewidth=3, linestyle=\":\", markersize=8)\n",
    "\n",
    "plt.xlabel('Recall', fontsize=14)\n",
    "plt.ylabel('Precision', fontsize=14)\n",
    "plt.title('Precision-Recall Curve \\n(test_set=04/2023)', fontsize=16)\n",
    "plt.grid(True)\n",
    "\n",
    "# Format axis values as percentages\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(mtick.MultipleLocator(base=0.01))\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=0))\n",
    "ax.yaxis.set_major_locator(mtick.MultipleLocator(base=0.001))\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=2))\n",
    "\n",
    "plt.ylim(0.004,0.018)\n",
    "\n",
    "# Add horizontal line for benchmark model\n",
    "benchmark_precision=0.0053\n",
    "plt.axhline(y=benchmark_precision, color=(0.8,0.7,0.5),linestyle='--', linewidth=3)\n",
    "\n",
    "# Set the legend\n",
    "plt.legend()\n",
    "plt.legend(models+[\"Lexican Search\"],bbox_to_anchor=(1,0.5), fontsize=14)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0233cd93-caad-4dd6-903b-0eae8e4021a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f858204b-0ec5-4dd6-b524-f22ac6cfa8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=0.95\n",
    "test_date=\"04_23\"\n",
    "\n",
    "model_name=\"randomforest\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/TFIDF/results/{test_date}/{model_name}/\"\n",
    "metrics=metrics_df_func(output_dir, model_name)\n",
    "metrics=metrics[metrics.recall>threshold]\n",
    "metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "\n",
    "model_name=\"xgboost\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/TFIDF/results/{test_date}/{model_name}/\"\n",
    "tempt=metrics_df_func(output_dir, model_name)\n",
    "tempt=tempt[tempt.recall>threshold]\n",
    "tempt.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "metrics=pd.concat([metrics,tempt],axis=0,ignore_index=True)\n",
    "\n",
    "model_name=\"lightgbm\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/TFIDF/results/{test_date}/{model_name}/\"\n",
    "tempt=metrics_df_func(output_dir, model_name)\n",
    "tempt=tempt[tempt.recall>threshold]\n",
    "tempt.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "metrics=pd.concat([metrics,tempt],axis=0,ignore_index=True)\n",
    "\n",
    "model_name=\"roberta_large\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "tempt=metrics_df_func(output_dir, model_name)\n",
    "tempt=tempt[tempt.recall>threshold]\n",
    "tempt.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "metrics=pd.concat([metrics,tempt],axis=0,ignore_index=True)\n",
    "\n",
    "model_name=\"deberta_v3_large\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "tempt=metrics_df_func(output_dir, model_name)\n",
    "tempt=tempt[tempt.recall>threshold]\n",
    "tempt.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "metrics=pd.concat([metrics,tempt],axis=0,ignore_index=True)\n",
    "\n",
    "model_name=\"longformer_base_4096_customized\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "tempt=metrics_df_func(output_dir, \"longformer_base\")\n",
    "tempt=tempt[tempt.recall>threshold]\n",
    "tempt.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "metrics=pd.concat([metrics,tempt],axis=0,ignore_index=True)\n",
    "\n",
    "model_name=\"longformer_large_4096_customized\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "tempt=metrics_df_func(output_dir, \"longformer_large\")\n",
    "tempt=tempt[tempt.recall>threshold]\n",
    "tempt.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "metrics=pd.concat([metrics,tempt],axis=0,ignore_index=True)\n",
    "\n",
    "model_name=\"bigbird_roberta_large_customized\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "tempt=metrics_df_func(output_dir, \"bigbird\")\n",
    "tempt=tempt[tempt.recall>threshold]\n",
    "tempt.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "metrics=pd.concat([metrics,tempt],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4710614-d2a2-4f48-8d34-fe8c0ea42531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics.to_csv(\"metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0a9311-86bf-425b-84b7-02925956b708",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=metrics.drop([\"Recall in Val\"],axis=1)\n",
    "style_format(metrics,  type=\"Different Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9e7750-dc8e-4cf5-ab05-844129c5207d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc65e1ff-e507-4ba9-98bc-8fe033897b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=metrics.groupby(\"model_type\")[\"recall\"].idxmax()\n",
    "metrics_2=metrics.loc[idx]\n",
    "desired_order=[\"randomforest\",\"xgboost\",\"lightgbm\",\"roberta_large\",\"deberta_v3_large\",\"longformer_base\",\"longformer_large\",\"bigbird\"]\n",
    "metrics_2[\"model_type\"]=pd.Categorical(metrics_2[\"model_type\"],categories=desired_order,ordered=True)\n",
    "metrics_2=metrics_2.sort_values(by=\"model_type\")\n",
    "style_format(metrics_2,  type=\"Different Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded704f9-ee44-401a-b922-554c11d67106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41886990-2e3e-4eb2-bd87-5d00857e1d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision=[]\n",
    "recall=[]\n",
    "\n",
    "model=\"xgboost\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/TFIDF/results/04_23/{model}/\"\n",
    "df=metrics_df(output_dir, model)\n",
    "idx=df.groupby(\"model_type\")[\"recall\"].idxmax()\n",
    "precision.extend(df.loc[idx,\"precision\"].tolist())\n",
    "recall.extend(df.loc[idx,\"recall\"].tolist())\n",
    "\n",
    "model=\"lightgbm\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/TFIDF/results/04_23/{model}/\"\n",
    "df=metrics_df(output_dir, model)\n",
    "idx=df.groupby(\"model_type\")[\"recall\"].idxmax()\n",
    "precision.extend(df.loc[idx,\"precision\"].tolist())\n",
    "recall.extend(df.loc[idx,\"recall\"].tolist())\n",
    "\n",
    "model=\"randomforest\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/TFIDF/results/04_23/{model}/\"\n",
    "df=metrics_df(output_dir, model)\n",
    "idx=df.groupby(\"model_type\")[\"recall\"].idxmax()\n",
    "precision.extend(df.loc[idx,\"precision\"].tolist())\n",
    "recall.extend(df.loc[idx,\"recall\"].tolist())\n",
    "\n",
    "model=\"roberta_large_customized\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/04_23/{model}/\"\n",
    "df=metrics_df(output_dir, model)\n",
    "idx=df.groupby(\"model_type\")[\"recall\"].idxmax()\n",
    "precision.extend(df.loc[idx,\"precision\"].tolist())\n",
    "recall.extend(df.loc[idx,\"recall\"].tolist())\n",
    "\n",
    "model=\"deberta_v3_large\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/04_23/{model}/\"\n",
    "df=metrics_df(output_dir, model)\n",
    "idx=df.groupby(\"model_type\")[\"recall\"].idxmax()\n",
    "precision.extend(df.loc[idx,\"precision\"].tolist())\n",
    "recall.extend(df.loc[idx,\"recall\"].tolist())\n",
    "\n",
    "model=\"longformer_base_4096_customized\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/04_23/{model}/\"\n",
    "df=metrics_df(output_dir, model)\n",
    "idx=df.groupby(\"model_type\")[\"recall\"].idxmax()\n",
    "precision.extend(df.loc[idx,\"precision\"].tolist())\n",
    "recall.extend(df.loc[idx,\"recall\"].tolist())\n",
    "\n",
    "model=\"longformer_large_4096_customized\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/04_23/{model}/\"\n",
    "df=metrics_df(output_dir, model)\n",
    "idx=df.groupby(\"model_type\")[\"recall\"].idxmax()\n",
    "precision.extend(df.loc[idx,\"precision\"].tolist())\n",
    "recall.extend(df.loc[idx,\"recall\"].tolist())\n",
    "\n",
    "model=\"bigbird_roberta_large_customized\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/04_23/{model}/\"\n",
    "df=metrics_df(output_dir, model)\n",
    "idx=df.groupby(\"model_type\")[\"recall\"].idxmax()\n",
    "precision.extend(df.loc[idx,\"precision\"].tolist())\n",
    "recall.extend(df.loc[idx,\"recall\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4311c552-c280-429d-ac1c-a08ab8f883ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "# Define precision and recall values for each model\n",
    "models = ['TFIDF+xgboost','TFIDF+lightgbm','TFIDF+random-forest','roberta-large','deberta-v3-large','longformer-base', 'longformer-large', 'bigbird-large']\n",
    "\n",
    "markers = ['o', 's', 'D', 'x', '*', '<', 'p', '^']\n",
    "colors = ['blue', 'green', 'orange', 'red', 'brown','lawngreen', 'purple','black']\n",
    "\n",
    "# Plot precision and recall\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Iterate over models\n",
    "for i in range(len(models)):\n",
    "    plt.scatter(recall[i], precision[i], color=colors[i], marker=markers[i],label=models[i], s=100)\n",
    "    plt.annotate(models[i],(recall[i], precision[i]),xytext=(10,-2),textcoords=\"offset points\")\n",
    "    \n",
    "plt.ylim([0.003,0.015])\n",
    "plt.xlim([0.97,1.001])\n",
    "plt.xticks([0.97,0.98,0.99,1])\n",
    "plt.xlabel('Recall', fontsize=14)\n",
    "plt.ylabel('Precision', fontsize=14)\n",
    "plt.title('Precision-Recall Curve \\n(test_set=04/2023)', fontsize=16)\n",
    "plt.grid(True)\n",
    "\n",
    "# Format axis values as percentages\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=0))\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=2))\n",
    "\n",
    "# Set the legend\n",
    "plt.legend(bbox_to_anchor=(1.35,0.4))\n",
    "\n",
    "# # Add precision and recall values as annotations\n",
    "# for i in range(len(models)):\n",
    "#     for j in range(len(precision[i])):\n",
    "#         x = recall[i][j]\n",
    "#         y = precision[i][j]\n",
    "#         text = f'({precision[i][j]*100:.2f}%, {recall[i][j]*100:.2f}%)'\n",
    "#         plt.annotate(text, (x, y), textcoords=\"offset points\", xytext=(0, 10), ha='center')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69e3411-cd15-466c-b30c-3d3ae3e65318",
   "metadata": {},
   "source": [
    "### Top prediction score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6b01f7-8dc8-46c0-a371-43772d0dbeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_date=\"04_23\"\n",
    "\n",
    "model_name=\"randomforest\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/TFIDF/results/{test_date}/{model_name}/\"\n",
    "df=pd.read_csv(os.path.join(output_dir , \"predictions_9.csv\"))\n",
    "randomforest_true, randomforest_prob=df[\"True_label\"].tolist(), df[\"Predicted_prob\"].tolist()\n",
    "\n",
    "model_name=\"xgboost\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/TFIDF/results/{test_date}/{model_name}/\"\n",
    "df=pd.read_csv(os.path.join(output_dir , \"predictions_9.csv\"))\n",
    "xgboost_true, xgboost_prob=df[\"True_label\"].tolist(), df[\"Predicted_prob\"].tolist()\n",
    "\n",
    "model_name=\"lightgbm\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/TFIDF/results/{test_date}/{model_name}/\"\n",
    "df=pd.read_csv(os.path.join(output_dir , \"predictions_9.csv\"))\n",
    "lightgbm_true, lightgbm_prob=df[\"True_label\"].tolist(), df[\"Predicted_prob\"].tolist()\n",
    "\n",
    "model_name=\"roberta_large_customized\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "df=pd.read_csv(os.path.join(output_dir , \"predictions_9.csv\"))\n",
    "roberta_true, roberta_prob=df[\"True_label\"].tolist(), df[\"Predicted_prob\"].tolist()\n",
    "\n",
    "model_name=\"deberta_v3_large\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "df=pd.read_csv(os.path.join(output_dir , \"predictions_9.csv\"))\n",
    "deberta_v3_true, deberta_v3_prob=df[\"True_label\"].tolist(), df[\"Predicted_prob\"].tolist()\n",
    "\n",
    "# model_name=\"deberta_v2_xlarge\"\n",
    "# output_dir=f\"/opt/omniai/work/instance1/jupyter/v3_new_email/Fine-Tuning/results/{model_name}\"\n",
    "# df=pd.read_csv(os.path.join(output_dir , \"predictions_9.csv\"))\n",
    "# deberta_v2_true, deberta_v2_prob=df[\"True_label\"].tolist(), df[\"Predicted_prob\"].tolist()\n",
    "\n",
    "model_name=\"longformer_base_4096_customized\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "df=pd.read_csv(os.path.join(output_dir , \"predictions_9.csv\"))\n",
    "longformer_base_true, longformer_base_prob=df[\"True_label\"].tolist(), df[\"Predicted_prob\"].tolist()\n",
    "\n",
    "model_name=\"longformer_large_4096_customized\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "df=pd.read_csv(os.path.join(output_dir , \"predictions_9.csv\"))\n",
    "longformer_large_true, longformer_large_prob=df[\"True_label\"].tolist(), df[\"Predicted_prob\"].tolist()\n",
    "\n",
    "model_name=\"bigbird_roberta_large_customized\"\n",
    "output_dir=f\"/opt/omniai/work/instance1/jupyter/v4_new_email/Fine-Tuning/results/{test_date}/{model_name}/\"\n",
    "df=pd.read_csv(os.path.join(output_dir , \"predictions_9.csv\"))\n",
    "bigbird_true, bigbird_prob=df[\"True_label\"].tolist(), df[\"Predicted_prob\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a36e982-a92e-4d02-a2a2-14ec4dadb88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk=[0.01,0.02,0.05,0.1]\n",
    "\n",
    "response_lightgbm = response_rate_eval(lightgbm_prob,lightgbm_true, topk)\n",
    "response_xgboost = response_rate_eval(xgboost_prob,xgboost_true, topk)\n",
    "response_randomforest = response_rate_eval(randomforest_prob, randomforest_true, topk)\n",
    "\n",
    "response_deberta_v3 = response_rate_eval(deberta_v3_prob, deberta_v3_true, topk)\n",
    "response_roberta = response_rate_eval(roberta_prob, roberta_true, topk)\n",
    "response_longformer_base = response_rate_eval(longformer_base_prob, longformer_base_true, topk)\n",
    "response_longformer_large = response_rate_eval(longformer_large_prob, longformer_large_true, topk)\n",
    "response_bigbird = response_rate_eval(bigbird_prob, bigbird_true, topk)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = {\n",
    "        \"tfidf+lightgbm\": response_lightgbm,\n",
    "        \"tfidf+xgboost\": response_xgboost,\n",
    "        \"tfidf+random-forest\": response_randomforest,\n",
    "        \"roberta_large\": response_roberta,\n",
    "        \"deberta_v3_large\": response_deberta_v3,\n",
    "        \"longformer-base\": response_longformer_base,\n",
    "        \"longformer-large\": response_longformer_large,\n",
    "        \"bigbird-large\": response_bigbird\n",
    "    }\n",
    "\n",
    "    \n",
    "    CL=['r', 'g', 'b', 'c', 'y', 'darkorange', 'lime', 'grey','gold','bisque', 'lightseagreen', 'purple']\n",
    "    bar_plot(data, colors=CL,total_width=.7, single_width=1,title=\"(response rate)\",subtitle=\"Test Set \",axis_truncation=0.50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7026e29d-89df-47c5-b99a-3449a6c30157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469d158e-2db2-4842-b57e-b7a3a1da9ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_mask_creation(dataset,target_variable, validation_split):\n",
    "    \n",
    "    dataset.sort_values(by='time', ascending=False, axis=0, inplace = True)\n",
    "    dataset=dataset.reset_index(drop=True)\n",
    "    \n",
    "    train_idx=[]\n",
    "    val_idx=[]\n",
    "    \n",
    "    LABEL=dataset[target_variable].values.squeeze()\n",
    "    IDX=np.arange(LABEL.shape[0])\n",
    "    target_list=np.unique(LABEL).tolist()\n",
    "        \n",
    "    for i in range(len(target_list)):\n",
    "        \n",
    "        _idx=IDX[LABEL==target_list[i]]\n",
    "        ## split train and valiation by time instead of randomly\n",
    "        # np.random.seed(seed)\n",
    "        # np.random.shuffle(_idx)\n",
    "        \n",
    "        split=int(np.floor(validation_split*_idx.shape[0]))\n",
    "        \n",
    "        val_idx.extend(_idx[ : split])\n",
    "        print(len(_idx[ : split]))\n",
    "        train_idx.extend(_idx[split:])        \n",
    " \n",
    "    all_idx=np.arange(LABEL.shape[0])\n",
    "\n",
    "    val_idx=np.array(val_idx)\n",
    "    train_idx=np.array(train_idx)\n",
    "    \n",
    "    df_train=dataset.loc[train_idx,:]\n",
    "    df_val=dataset.loc[val_idx,:]\n",
    "    df_val[\"data_type\"]=[\"val\"]*val_idx.shape[0]\n",
    "    \n",
    "    return df_train, df_val\n",
    "\n",
    "data_path=os.path.join(\"/opt/omniai/work/instance1/jupyter/\", \"v3_new_email\",\"datasets\",\"split_data\")\n",
    "data_name=[x for x in os.listdir(data_path) if x.split(\"_\")[-2]==\"pickle\"]\n",
    "df=pd.DataFrame()\n",
    "for data in data_name:\n",
    "    x=pd.read_pickle(os.path.join(data_path,data))\n",
    "    df=pd.concat([df,x],axis=0,ignore_index=True)\n",
    "    # print(\"{:<20}{:<20,}\".format(data.split(\"_\")[-1],x.shape[0]))\n",
    "\n",
    "### only keep emails with status=closed\n",
    "df=df[df.state==\"closed\"]\n",
    "\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df.sort_values(by='time', inplace = True) \n",
    "## train: 09/2022 ~ 01/2023. validation: 02/2023  test: 03/2023\n",
    "set_categories=lambda row: \"train\" if (row[\"year\"] in [2022,2023] and row[\"month\"] in [9,10,11,12,1,2,3]) else \"test\"\n",
    "df[\"data_type\"]=df.progress_apply(set_categories,axis=1)\n",
    "df.loc[:,'target']=df.loc[:,'is_complaint'].progress_apply(lambda x: 1 if x==\"Y\" else 0)\n",
    "df.loc[:,'is_feedback']=df.loc[:,'is_feedback'].progress_apply(lambda x: 1 if x==\"Y\" else 0)\n",
    "\n",
    "df1=df[df.data_type==\"train\"]\n",
    "df1=df1.reset_index(drop=True)\n",
    "df_train,df_val=val_mask_creation(df1,'is_complaint', validation_split=0.2)\n",
    "\n",
    "df_test=df[df.data_type==\"test\"]\n",
    "df=pd.concat([df_train,df_val,df_test],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b8ad78-5160-4f2d-aa8d-79b5ab25b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_distribution(df,data_type):\n",
    "    df=df[df[\"data_type\"]==data_type]\n",
    "    tempt1=pd.DataFrame(df[\"is_complaint\"].value_counts(dropna=False)).reset_index().rename(columns={'index':'is_complaint','is_complaint':'count'})\n",
    "    tempt2=pd.DataFrame(df[\"is_complaint\"].value_counts(dropna=False,normalize=True)).reset_index().rename(columns={'index':'is_complaint','is_complaint':'percentage'})\n",
    "    tempt3=tempt1.merge(tempt2, on=\"is_complaint\", how=\"inner\")\n",
    "    tempt3['data_type']=data_type\n",
    "    tempt3=tempt3.loc[:,['data_type','is_complaint','count','percentage']]\n",
    "    return tempt3\n",
    "\n",
    "def style_format(df):\n",
    "    return df.style.format({'count':'{:,}','percentage':'{:.2%}'})\\\n",
    "           .set_caption(f\"label distribution\")\\\n",
    "           .set_table_styles([{'selector': 'caption','props': [('color', 'red'),('font-size', '15px')]}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf0decf-27ac-40e4-8a85-7f98b0d1f3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df=pd.DataFrame()\n",
    "dist_df=pd.concat([dist_df,label_distribution(df,\"train\")])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df,\"val\")])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df,\"test\")])\n",
    "style_format(dist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b918300-1dc6-4703-9240-43d0a84246e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt0",
   "language": "python",
   "name": "pt0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
