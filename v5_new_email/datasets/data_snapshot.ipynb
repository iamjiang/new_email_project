{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df2a810-552e-4c41-9f23-9faa76e2b8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import savez_compressed, load\n",
    "import itertools\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset, load_metric, Dataset, concatenate_datasets,DatasetDict\n",
    "from datasets import load_from_disk\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(position=0,leave=True)\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "# Load the stopwords from the new directory\n",
    "nltk_data_dir=os.path.join(\"/opt/omniai/work/instance1/jupyter/\", \"transformers-models\",\"nltk_data\")\n",
    "stopwords_file = open(nltk_data_dir + '/corpora/stopwords/english')\n",
    "stopwords_list = stopwords_file.readlines()\n",
    "nltk.data.path.append(nltk_data_dir)\n",
    "\n",
    "# import spacy\n",
    "# model_name=os.path.join(\"/opt/omniai/work/instance1/jupyter/\", \"transformers-models\",\"en_core_web_md\",\"en_core_web_md-3.3.0\")\n",
    "# nlp = spacy.load(model_name)\n",
    "\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "sns.set(style=\"whitegrid\",palette='muted',font_scale=1.2)\n",
    "rcParams['figure.figsize']=16,10\n",
    "\n",
    "%config InlineBackend.figure_format=\"retina\"\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', None,'display.max_rows',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30672b81-271e-47b3-98bc-d9b2bd1b5c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir=\"/opt/omniai/work/instance1/jupyter/v5_new_email/datasets/raw_data\"\n",
    "data_name=[x for x in os.listdir(root_dir) if x.split(\".\")[-1]==\"csv\"]\n",
    "df=pd.DataFrame()\n",
    "for data in data_name:\n",
    "    x=pd.read_csv(os.path.join(root_dir,data))\n",
    "    x=x.dropna(subset=['email'])\n",
    "    x=x[x.email.notna()]\n",
    "    x=x[x.email.str.len()>0]\n",
    "    df=pd.concat([df,x],axis=0,ignore_index=True)\n",
    "    print(\"{:<20}{:<20,}\".format(data.split(\"_\")[2],x.shape[0]))\n",
    "    \n",
    "df=df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9ce2a0-e83e-43be-9678-302c0c6477a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df.state==\"closed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80745fb6-4c62-4c94-ac0f-6af3acfcaeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df['year'] = df.time.apply(lambda x: x.year)\n",
    "df['month'] = df.time.apply(lambda x: x.month)\n",
    "df['day'] = df.time.apply(lambda x: x.day)\n",
    "df.sort_values(by='time', inplace = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1818ba-7f71-41ba-92e2-de7524430e64",
   "metadata": {},
   "source": [
    "#### remove duplicated emails based on thread id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deb27c4-08c3-4e1f-946a-bf3069c0d21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df=df.groupby('thread_id')\n",
    "sorted_groups=[group.sort_values(\"time\",ascending=False).reset_index(drop=True) for _, group in grouped_df]\n",
    "df=pd.concat(sorted_groups).drop_duplicates(subset=\"thread_id\", keep=\"first\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abf3436-a580-4f64-b466-4f394b08eb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_distribution(df,year,month):\n",
    "    df=df[(df.year==year) & (df.month==month)]\n",
    "    tempt1=pd.DataFrame(df[\"is_complaint\"].value_counts(dropna=False)).reset_index().rename(columns={'index':'is_complaint','is_complaint':'count'})\n",
    "    tempt2=pd.DataFrame(df[\"is_complaint\"].value_counts(dropna=False,normalize=True)).reset_index().rename(columns={'index':'is_complaint','is_complaint':'percentage'})\n",
    "    tempt3=tempt1.merge(tempt2, on=\"is_complaint\", how=\"inner\")\n",
    "    tempt3['year']=year\n",
    "    tempt3['month']=month\n",
    "    tempt3=tempt3.loc[:,['year','month','is_complaint','count','percentage']]\n",
    "    return tempt3\n",
    "\n",
    "def style_format(df,  data_type=\"Training set\"):\n",
    "    return df.style.format({'count':'{:,}','percentage':'{:.2%}'})\\\n",
    "           .set_caption(f\"label distribution\\n{data_type}\")\\\n",
    "           .set_table_styles([{'selector': 'caption','props': [('color', 'red'),('font-size', '15px')]}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6165c47-c0ed-4e2a-b098-0386e51e0e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df=pd.DataFrame()\n",
    "# dist_df=pd.concat([dist_df,label_distribution(df,2022,8)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df,2022,9)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df,2022,10)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df,2022,11)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df,2022,12)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df,2023,1)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df,2023,2)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df,2023,3)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df,2023,4)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df,2023,5)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df,2023,6)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df,2023,7)])\n",
    "style_format(dist_df,  data_type=\"split by month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f253d8-96ab-4bc9-942c-027edd49bd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## train: 09/2022 ~ 03/2023. validation: 04/2023  test: 05/2023\n",
    "# set_categories=lambda row: \"train\" if (row[\"year\"] in [2022,2023] and row[\"month\"] in [9,10,11,12,1,2,3]) \\\n",
    "# else (\"val\" if (row[\"year\"]==2023 and row[\"month\"]==4) else \"test\")\n",
    "\n",
    "# df[\"data_type\"]=df1.progress_apply(set_categories,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f3d1d8-97ed-4bab-9a67-18da9fb631fe",
   "metadata": {},
   "source": [
    "### After data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e6e3d6-e721-47cd-91e4-d6901dbd687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir=\"/opt/omniai/work/instance1/jupyter/v5_new_email/datasets/split_data\"\n",
    "# data_name=[x for x in os.listdir(root_dir) if x.split(\"_\")[-2]==\"pickle\"]\n",
    "# df1=pd.DataFrame()\n",
    "# for data in data_name:\n",
    "#     x=pd.read_pickle(os.path.join(root_dir,data))\n",
    "#     x=x.dropna(subset=['email'])\n",
    "#     x=x[x.email.notna()]\n",
    "#     x=x[x.email.str.len()>0]\n",
    "#     df1=pd.concat([df1,x],axis=0,ignore_index=True)\n",
    "#     # print(\"{:<20}{:<20,}\".format(data.split(\"_\")[2],x.shape[0]))\n",
    "    \n",
    "# df1=df1.reset_index(drop=True)\n",
    "\n",
    "root_dir=\"/opt/omniai/work/instance1/jupyter/v5_new_email/datasets\"\n",
    "df1=pd.read_pickle(os.path.join(root_dir,\"train_val_test_pickle\"))\n",
    "\n",
    "df1['time'] = pd.to_datetime(df1['time'])\n",
    "df1['year'] = df1.time.apply(lambda x: x.year)\n",
    "df1['month'] = df1.time.apply(lambda x: x.month)\n",
    "df1['day'] = df1.time.apply(lambda x: x.day)\n",
    "df1.sort_values(by='time', inplace = True) \n",
    "\n",
    "# grouped_df=df1.groupby('thread_id')\n",
    "# sorted_groups=[group.sort_values(\"time\",ascending=False).reset_index(drop=True) for _, group in grouped_df]\n",
    "# df1=pd.concat(sorted_groups).drop_duplicates(subset=\"thread_id\", keep=\"first\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35beed92-d354-4dbc-84ce-ec12f261ab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"is_complaint\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5481be1-197a-4428-bfdc-c686b6ca6746",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df=pd.DataFrame()\n",
    "# dist_df=pd.concat([dist_df,label_distribution(df1,2022,8)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,2022,9)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,2022,10)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,2022,11)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,2022,12)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,2023,1)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,2023,2)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,2023,3)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,2023,4)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,2023,5)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,2023,6)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,2023,7)])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,2023,8)])\n",
    "style_format(dist_df,  data_type=\"split by month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b659b7b-13d8-4d0c-880b-24b111ec5a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_test_month=pd.DataFrame({\"data_type\":[\"train\",\"val\",\"test\"],\\\n",
    "                                   \"month\":[\"09/22 ~ 07/23\",\"09/22 ~ 07/23\",\"08/23\"],\\\n",
    "                                  \"split\":[\"80%\",\"20%\",\"\"]})\n",
    "train_val_test_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8c1da0-7c1d-4009-90dd-085dd03d9815",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train: 09/2022 ~ 03/2023. validation: 04/2023  test: 05/2023\n",
    "set_categories=lambda row: \"train\" if (row[\"year\"] in [2022,2023] and row[\"month\"] in [9,10,11,12,1,2,3]) \\\n",
    "else (\"val\" if (row[\"year\"]==2023 and row[\"month\"]==4) else \"test\")\n",
    "\n",
    "df1[\"data_type\"]=df1.progress_apply(set_categories,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcf4835-924e-49de-8ddb-ba965183c3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_distribution(df,data_type):\n",
    "    df=df[df[\"data_type\"]==data_type]\n",
    "    tempt1=pd.DataFrame(df[\"is_complaint\"].value_counts(dropna=False)).reset_index().rename(columns={'index':'is_complaint','is_complaint':'count'})\n",
    "    tempt2=pd.DataFrame(df[\"is_complaint\"].value_counts(dropna=False,normalize=True)).reset_index().rename(columns={'index':'is_complaint','is_complaint':'percentage'})\n",
    "    tempt3=tempt1.merge(tempt2, on=\"is_complaint\", how=\"inner\")\n",
    "    tempt3['data_type']=data_type\n",
    "    tempt3=tempt3.loc[:,['data_type','is_complaint','count','percentage']]\n",
    "    return tempt3\n",
    "\n",
    "def style_format(df):\n",
    "    return df.style.format({'count':'{:,}','percentage':'{:.2%}'})\\\n",
    "           .set_caption(f\"label distribution\")\\\n",
    "           .set_table_styles([{'selector': 'caption','props': [('color', 'red'),('font-size', '15px')]}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3f4e12-6042-4b66-8070-d5b4e6479e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df=pd.DataFrame()\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,\"train\")])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,\"val\")])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df1,\"test\")])\n",
    "style_format(dist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed84b474-21d8-474a-b270-cc3a406edcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedback_distribution(df):\n",
    "    tempt1=df.groupby('is_feedback')['is_complaint'].value_counts(dropna=False).reset_index(name=\"count\")\n",
    "    tempt2=df.groupby('is_feedback')['is_complaint'].value_counts(dropna=False,normalize=True).reset_index(name=\"percentage\")\n",
    "    tempt3=tempt1.merge(tempt2, on=['is_feedback',\"is_complaint\"], how=\"inner\")\n",
    "    tempt3=tempt3.loc[:,['is_feedback','is_complaint','count','percentage']]\n",
    "    return tempt3\n",
    "\n",
    "def style_format(df):\n",
    "    return df.style.format({'count':'{:,}','percentage':'{:.2%}'})\\\n",
    "           .set_caption(f\"feedback distribution\")\\\n",
    "           .set_table_styles([{'selector': 'caption','props': [('color', 'red'),('font-size', '15px')]}])\n",
    "\n",
    "dist_df=feedback_distribution(df1)\n",
    "style_format(dist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dc520c-2ac1-4268-ba23-3ba65e12924d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f54b38d-bcc1-42d0-9253-7457d6513875",
   "metadata": {},
   "source": [
    "### email text length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a62d8b-029a-4a84-a09f-18b8d5af416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset, load_metric, Dataset, concatenate_datasets,DatasetDict\n",
    "from datasets import load_from_disk\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(position=0,leave=True)\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name=\"longformer-base-4096\"\n",
    "model_path=os.path.join(\"/opt/omniai/work/instance1/jupyter/\", \"transformers-models\",model_name)\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
    "print()\n",
    "print(f\"Vocabulary size : {tokenizer.vocab_size:,}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bb9e08-15d6-4cc2-885c-1b616e8766db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_hf(df):\n",
    "   \n",
    "    train_df=df[df[\"data_type\"]==\"train\"]\n",
    "    val_df=df[df[\"data_type\"]==\"val\"]\n",
    "    test_df=df[df[\"data_type\"]==\"test\"]\n",
    "    \n",
    "    hf_train=Dataset.from_pandas(train_df)\n",
    "    hf_val=Dataset.from_pandas(val_df)\n",
    "    hf_test=Dataset.from_pandas(test_df)\n",
    "    \n",
    "    hf_data=DatasetDict({\"train\":hf_train, \"val\":hf_val,  \"test\":hf_test})\n",
    "    # hf_data=hf_data.select_columns(['snapshot_id','thread_id','time','preprocessed_email','is_feedback','is_complaint'])\n",
    "    \n",
    "    return hf_data\n",
    "\n",
    "hf_v0=dataframe_hf(df)\n",
    "hf_v1=dataframe_hf(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67456b5e-46c0-4204-b6c2-d5ac4934182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lenth(example):\n",
    "    return {\"text_length\":len(example[\"input_ids\"])}\n",
    "\n",
    "hf_v0=hf_v0.map(lambda x: tokenizer(x[\"email\"]),batched=True)\n",
    "hf_v0=hf_v0.map(compute_lenth)\n",
    "\n",
    "hf_v1=hf_v1.map(lambda x: tokenizer(x[\"preprocessed_email\"]),batched=True)\n",
    "hf_v1=hf_v1.map(compute_lenth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc42937-2c62-40d8-b403-10152c885138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics_compute(hf_df1,hf_df2,hf_df3,p=1):\n",
    "\n",
    "    X=[]\n",
    "    X.append(np.percentile(hf_df1['text_length'],p))\n",
    "    X.append(np.percentile(hf_df2['text_length'],p))\n",
    "    X.append(np.percentile(hf_df3['text_length'],p))\n",
    "    \n",
    "    result={}\n",
    "    result['percentile']=X\n",
    "    result[\"min\"]=[np.min(hf_df1['text_length']),np.min(hf_df2['text_length']),np.min(hf_df3['text_length'])]\n",
    "    result[\"max\"]=[np.max(hf_df1['text_length']),np.max(hf_df2['text_length']),np.max(hf_df3['text_length'])]\n",
    "    result[\"mean\"]=[np.mean(hf_df1['text_length']),np.mean(hf_df2['text_length']),np.mean(hf_df3['text_length'])]\n",
    "    return result\n",
    "\n",
    "def statistics_table(hf_df1,hf_df2,hf_df3):\n",
    "    dict_data={}\n",
    "    dict_data[\"data_type\"]=[\"training\", \"validation\", \"test\"]\n",
    "    dict_data[\"# of obs\"]=[len(hf_df1['text_length']),len(hf_df2['text_length']),len(hf_df3['text_length'])]\n",
    "    dict_data[\"Min of tokens\"]=statistics_compute(hf_df1, hf_df2, hf_df3)[\"min\"]\n",
    "    dict_data[\"1% of tokens\"]=statistics_compute(hf_df1, hf_df2, hf_df3, p=1)['percentile']\n",
    "    dict_data[\"5% of tokens\"]=statistics_compute(hf_df1, hf_df2, hf_df3, p=5)['percentile']\n",
    "    dict_data[\"10% of tokens\"]=statistics_compute(hf_df1, hf_df2, hf_df3, p=10)['percentile']\n",
    "    dict_data[\"25% of tokens\"]=statistics_compute(hf_df1, hf_df2, hf_df3, p=25)['percentile']\n",
    "    dict_data[\"Median of tokens\"]=statistics_compute(hf_df1, hf_df2, hf_df3, p=50)['percentile']\n",
    "    dict_data[\"Average tokens\"]=statistics_compute(hf_df1, hf_df2, hf_df3)[\"mean\"]\n",
    "    dict_data[\"75% of tokens\"]=statistics_compute(hf_df1, hf_df2, hf_df3, p=75)['percentile']\n",
    "    dict_data[\"90% of tokens\"]=statistics_compute(hf_df1, hf_df2, hf_df3, p=90)['percentile']\n",
    "    dict_data[\"95% of tokens\"]=statistics_compute(hf_df1, hf_df2, hf_df3, p=95)['percentile']\n",
    "    dict_data[\"99% of tokens\"]=statistics_compute(hf_df1, hf_df2, hf_df3, p=99)['percentile']\n",
    "    dict_data[\"Max of tokens\"]=statistics_compute(hf_df1, hf_df2, hf_df3)[\"max\"]\n",
    "    token_count_df=pd.DataFrame(dict_data)\n",
    "    return token_count_df\n",
    "\n",
    "def style_format(token_count_df,  textbody=\"preprocessed_email\"):\n",
    "    token_count_df=token_count_df.set_index(\"data_type\")\n",
    "    token_count_df[list(token_count_df.columns)] = token_count_df[list(token_count_df.columns)].astype(int)\n",
    "    return token_count_df.style.format(\"{:,}\").set_caption(f\"Summary Statistics of token lengths for {textbody} \").set_table_styles([{\n",
    "        'selector': 'caption',\n",
    "        'props': [\n",
    "            ('color', 'red'),\n",
    "            ('font-size', '15px')\n",
    "        ]\n",
    "    }])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3c1626-089c-4ed6-bf14-2d89bbc05496",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_count_df=statistics_table(hf_v0[\"train\"],hf_v0[\"val\"],hf_v0[\"test\"])\n",
    "style_format(token_count_df,  textbody=\"email data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054b5af0-3069-44c3-a09d-02c5ee3b9d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_count_df=statistics_table(hf_v1[\"train\"],hf_v1[\"val\"],hf_v1[\"test\"])\n",
    "style_format(token_count_df,  textbody=\"preprocessed email\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae42310a-9a1d-44a8-8e96-9f8d39c7f69b",
   "metadata": {},
   "source": [
    "### text length distribution for complaint email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6273ca-ba53-4b7d-86ab-efef97b1aaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_count_df=statistics_table(hf_v1[\"train\"].filter(lambda x : x[\"is_complaint\"]==\"Y\"), \\\n",
    "                                hf_v1[\"val\"].filter(lambda x : x[\"is_complaint\"]==\"Y\"),\\\n",
    "                                hf_v1[\"test\"].filter(lambda x : x[\"is_complaint\"]==\"Y\"))\n",
    "style_format(token_count_df,  textbody=\"Complaint email\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6f10a1-a0d6-4c02-83f2-e93129099452",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_count_df=statistics_table(hf_v1[\"train\"].filter(lambda x : x[\"is_complaint\"]==\"N\"), \\\n",
    "                                hf_v1[\"val\"].filter(lambda x : x[\"is_complaint\"]==\"N\"),\\\n",
    "                                hf_v1[\"test\"].filter(lambda x : x[\"is_complaint\"]==\"N\"))\n",
    "style_format(token_count_df,  textbody=\"Non-complaint email\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fdccad-30ec-44e4-8666-37c52eb2cb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcut_func(df,var,nbin=5):\n",
    "    df[var]=df[var].astype(float)\n",
    "    df[\"cut\"]=pd.qcut(df[var],nbin,precision=2,duplicates=\"drop\")\n",
    "    decile=df.groupby(df[\"cut\"])['target'].mean().reset_index()\n",
    "    decile[\"cut\"]=decile[\"cut\"].astype(str)\n",
    "    return decile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6472ddf7-5971-4338-9c6b-ed6649ed77c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=hf_v1[\"train\"]\n",
    "val_df=hf_v1[\"val\"]\n",
    "test_df=hf_v1[\"test\"]\n",
    "\n",
    "train_df.set_format(\"pandas\")\n",
    "df_train=train_df[:]\n",
    "df_train[\"target\"]=df_train['is_complaint'].apply(lambda x : 1 if x==\"Y\" else 0)\n",
    "\n",
    "val_df.set_format(\"pandas\")\n",
    "df_val=val_df[:]\n",
    "df_val[\"target\"]=df_val['is_complaint'].apply(lambda x : 1 if x==\"Y\" else 0)\n",
    "\n",
    "test_df.set_format(\"pandas\")\n",
    "df_test=test_df[:]\n",
    "df_test[\"target\"]=df_test['is_complaint'].apply(lambda x : 1 if x==\"Y\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74ddc31-d88b-445e-a766-2c0f7ea38d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def y_formatter(x,_):\n",
    "    return f'{x*100:.2f}%'\n",
    "fig, ax = plt.subplots(1,3,figsize=(15,6))\n",
    "plt.subplot(1,3,1)\n",
    "df=pcut_func(df_train,var=\"text_length\",nbin=10)\n",
    "ax[0].plot(df[\"cut\"],df[\"target\"],color=\"r\",marker=\"*\",linewidth=2, markersize=12)\n",
    "ax[0].set_title(\"text_length\\n(training set)\")\n",
    "ax[0].set_ylabel(\"complaint %\")\n",
    "ax[0].tick_params(labelrotation=45)\n",
    "ax[0].yaxis.set_major_formatter(ticker.FuncFormatter(y_formatter))\n",
    "plt.subplot(1,3,2)\n",
    "df=pcut_func(df_val,var=\"text_length\",nbin=10)\n",
    "ax[1].plot(df[\"cut\"],df[\"target\"],color=\"r\",marker=\"*\",linewidth=2, markersize=12)\n",
    "ax[1].set_title(\"text_length\\n(validation set)\")\n",
    "ax[1].set_ylabel(\"complaint %\")\n",
    "ax[1].tick_params(labelrotation=45)\n",
    "ax[1].yaxis.set_major_formatter(ticker.FuncFormatter(y_formatter))\n",
    "plt.subplot(1,3,3)\n",
    "df=pcut_func(df_test,var=\"text_length\",nbin=10)\n",
    "ax[2].plot(df[\"cut\"],df[\"target\"],color=\"r\",marker=\"*\",linewidth=2, markersize=12)\n",
    "ax[2].set_title(\"text_length\\n(test set)\")\n",
    "ax[2].set_ylabel(\"complaint %\")\n",
    "ax[2].tick_params(labelrotation=45)\n",
    "ax[2].yaxis.set_major_formatter(ticker.FuncFormatter(y_formatter))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c211d8-ed7a-4b7f-8cd2-7336b8d3d450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "164c679b-6053-4e0e-8188-9e0712074bd2",
   "metadata": {},
   "source": [
    "### short and long email "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe1a6fc-7197-486c-9a5c-e9819e566966",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir=\"/opt/omniai/work/instance1/jupyter/v2_new_email/datasets/split_data\"\n",
    "data_name=[x for x in os.listdir(root_dir) if x.split(\"_\")[-2]==\"pickle\"]\n",
    "df1=pd.DataFrame()\n",
    "for data in data_name:\n",
    "    x=pd.read_pickle(os.path.join(root_dir,data))\n",
    "    x=x.dropna(subset=['email'])\n",
    "    x=x[x.email.notna()]\n",
    "    x=x[x.email.str.len()>0]\n",
    "    df1=pd.concat([df1,x],axis=0,ignore_index=True)\n",
    "    # print(\"{:<20}{:<20,}\".format(data.split(\"_\")[2],x.shape[0]))\n",
    "    \n",
    "df1=df1.reset_index(drop=True)\n",
    "\n",
    "df1['time'] = pd.to_datetime(df1['time'])\n",
    "df1['year'] = df1.time.apply(lambda x: x.year)\n",
    "df1['month'] = df1.time.apply(lambda x: x.month)\n",
    "df1['day'] = df1.time.apply(lambda x: x.day)\n",
    "df1.sort_values(by='time', inplace = True) \n",
    "\n",
    "### only keep emails with status=closed\n",
    "df1=df1[df1.state==\"closed\"]\n",
    "\n",
    "## train: 09/2022 ~ 02/2023. validation: 03/2023  test: 04/2023\n",
    "set_categories=lambda row: \"train\" if (row[\"year\"] in [2022,2023] and row[\"month\"] in [9,10,11,12,1,2]) \\\n",
    "else (\"val\" if (row[\"year\"]==2023 and row[\"month\"]==3) else \"test\")\n",
    "df1[\"data_type\"]=df1.progress_apply(set_categories,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22411045-4cbd-4c57-8fc2-ff982e7a1625",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"long_short\"]=df1['text_length'].progress_apply(lambda x : 1 if x>512 else 0)\n",
    "df_short=df1[df1[\"long_short\"]==0]\n",
    "df_long=df1[df1[\"long_short\"]==1]\n",
    "\n",
    "df_short.drop(\"long_short\", axis=1, inplace=True)\n",
    "df_short=df_short.reset_index(drop=True)\n",
    "\n",
    "df_long.drop(\"long_short\", axis=1, inplace=True)\n",
    "df_long=df_long.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e7868b-d674-4375-b9a6-6fa05f6ff879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_distribution(df,data_type):\n",
    "    df=df[df[\"data_type\"]==data_type]\n",
    "    tempt1=pd.DataFrame(df[\"is_complaint\"].value_counts(dropna=False)).reset_index().rename(columns={'index':'is_complaint','is_complaint':'count'})\n",
    "    tempt2=pd.DataFrame(df[\"is_complaint\"].value_counts(dropna=False,normalize=True)).reset_index().rename(columns={'index':'is_complaint','is_complaint':'percentage'})\n",
    "    tempt3=tempt1.merge(tempt2, on=\"is_complaint\", how=\"inner\")\n",
    "    tempt3['data_type']=data_type\n",
    "    tempt3=tempt3.loc[:,['data_type','is_complaint','count','percentage']]\n",
    "    return tempt3\n",
    "\n",
    "def style_format(df, title):\n",
    "    return df.style.format({'count':'{:,}','percentage':'{:.2%}'})\\\n",
    "           .set_caption(f\"{title}\")\\\n",
    "           .set_table_styles([{'selector': 'caption','props': [('color', 'red'),('font-size', '15px')]}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929e9775-9cde-4543-9dad-cf73fb5cd675",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df=pd.DataFrame()\n",
    "dist_df=pd.concat([dist_df,label_distribution(df_short,\"train\")])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df_short,\"val\")])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df_short,\"test\")])\n",
    "style_format(dist_df,title=f\"label distribution for short email\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d92641-3187-4b85-8993-b14c70aa2518",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df=pd.DataFrame()\n",
    "dist_df=pd.concat([dist_df,label_distribution(df_long,\"train\")])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df_long,\"val\")])\n",
    "dist_df=pd.concat([dist_df,label_distribution(df_long,\"test\")])\n",
    "style_format(dist_df,title=\"label distribution for long email\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef9e5de-2924-4b0b-b212-cbbb9241826f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt0",
   "language": "python",
   "name": "pt0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
