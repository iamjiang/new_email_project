{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cd0b3e-9b27-4075-be35-f7ff3c15c7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4448f09a-55ff-4ae9-aa7b-1417766304ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_output(file_name):\n",
    "    with open(file_name,\"r\") as file:\n",
    "        epochs=[]\n",
    "        train_perplexity=[]\n",
    "        val_perplexity=[]\n",
    "        for line in file:\n",
    "            x,y,z=line.strip().split(',')\n",
    "            epochs.append(int(x))\n",
    "            train_perplexity.append(float(y))\n",
    "            val_perplexity.append(float(z))\n",
    "    return epochs, train_perplexity, val_perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264fd44c-bc77-4d46-9d9e-306f597022e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"longformer-base\"\n",
    "output_dir=model_name.split(\"-\")[0] + \"_\" + model_name.split(\"-\")[1] + \"_repo\"\n",
    "file_name=os.path.join(os.getcwd(),output_dir,\"Perplexity.txt\")\n",
    "epochs, _, longformer_base_perplexity=read_output(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6a711b-8699-4cb0-9420-497ae501060a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"longformer-large\"\n",
    "output_dir=model_name.split(\"-\")[0] + \"_\" + model_name.split(\"-\")[1] + \"_repo\"\n",
    "file_name=os.path.join(os.getcwd(),output_dir,\"Perplexity.txt\")\n",
    "epochs, _, longformer_large_perplexity=read_output(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d46b38-7235-4f31-ac5b-753ec15e2a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"roberta-base\"\n",
    "output_dir=model_name.split(\"-\")[0] + \"_\" + model_name.split(\"-\")[1] + \"_repo\"\n",
    "file_name=os.path.join(os.getcwd(),output_dir,\"Perplexity.txt\")\n",
    "epochs, _, roberta_base_perplexity=read_output(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47fad3e-27bf-4dc2-a956-1f273527f976",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"roberta-large\"\n",
    "output_dir=model_name.split(\"-\")[0] + \"_\" + model_name.split(\"-\")[1] + \"_repo\"\n",
    "file_name=os.path.join(os.getcwd(),output_dir,\"Perplexity.txt\")\n",
    "epochs, _, roberta_large_perplexity=read_output(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0490289-2cbe-4e28-a1f8-caa133dcd39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"bigbird-roberta-large\"\n",
    "output_dir=model_name.split(\"-\")[0] + \"_\" + model_name.split(\"-\")[1] + \"_repo\"\n",
    "file_name=os.path.join(os.getcwd(),output_dir,\"Perplexity.txt\")\n",
    "epochs, _, bigbird_roberta_perplexity=read_output(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6635c16f-a1b5-488e-ae63-f2418d9f9969",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot each model's performance over time as a line chart\n",
    "plt.plot(epochs[:len(roberta_base_perplexity)], roberta_base_perplexity, label='roberta-base', color='purple', linewidth=2, linestyle='-', marker=\"D\")\n",
    "plt.plot(epochs[:len(roberta_large_perplexity)], roberta_large_perplexity, label='roberta-large', color='blue', linewidth=2, linestyle='--', marker=\"o\")\n",
    "plt.plot(epochs[:len(longformer_base_perplexity)], longformer_base_perplexity, label='longformer-base', color='red', linewidth=2, linestyle=':', marker=\"s\")\n",
    "plt.plot(epochs[:len(longformer_large_perplexity)], longformer_large_perplexity, label='longformer-large', color='green', linewidth=2, linestyle='-.', marker=\"^\")\n",
    "# plt.plot(epochs[:len(bigbird_roberta_perplexity)], bigbird_roberta_perplexity, label='BigBird', color='orange', linewidth=2, linestyle='-.', marker=\">\")\n",
    "\n",
    "# Set chart title and axis labels\n",
    "plt.title('Perplexity over Epochs',fontsize=18)\n",
    "plt.xlabel('Epoch',fontsize=12)\n",
    "plt.ylabel('Perplexity',fontsize=12)\n",
    "plt.xticks(epochs)\n",
    "# Add a legend to the chart\n",
    "plt.legend()\n",
    "\n",
    "# Display the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d575495-a960-4c44-b8d4-d758478a476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/opt/omniai/work/instance1/jupyter/v3_new_email/Fine-Tuning\")\n",
    "sys.path=list(set(sys.path))\n",
    "\n",
    "path_to_remove=[\"/opt/omniai/work/instance1/jupyter/v2_new_email/\",\"/opt/omniai/work/instance1/jupyter/v2_new_email/Fine-Tuning\"]\n",
    "for path in path_to_remove:\n",
    "    if path in sys.path:\n",
    "        sys.path.remove(path)\n",
    "        \n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6a56d7-ba3f-4152-be4f-842f95631fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_read(df, model_name):\n",
    "    # df=pd.read_csv(os.path.join(output_dir , file_name))\n",
    "    true_y=df[\"True_label\"].values\n",
    "    pred_y=df[\"Predicted_label\"].values\n",
    "    pred_prob=df[\"Predicted_prob\"].values\n",
    "    best_threshold=df['best_threshold'].unique()[0]\n",
    "\n",
    "    # test_output=utils.model_evaluate(true_y.reshape(-1),pred_y)\n",
    "    test_output=utils.model_evaluate(true_y.reshape(-1),pred_prob,best_threshold)\n",
    "    metric=pd.DataFrame()\n",
    "    metric[\"model_type\"]=[f\"{model_name}\"]\n",
    "    metric[\"total complaint #\"]=[test_output[\"total positive\"]]\n",
    "    metric[\"false_positive\"]=[test_output[\"false positive\"]]\n",
    "    metric[\"false_negative\"]=[test_output[\"false_negative\"]]\n",
    "    metric[\"precision\"]=[test_output[\"precision\"]]\n",
    "    metric[\"recall\"]=[test_output[\"recall\"]]\n",
    "    metric[\"f1_score\"]=[test_output[\"f1_score\"]]\n",
    "    metric[\"roc_auc\"]=[test_output[\"AUC\"]]\n",
    "    metric[\"pr_auc\"]=[test_output[\"pr_auc\"]]\n",
    "    return metric\n",
    "\n",
    "def metrics_df(output_dir, model_name):\n",
    "    data_name=[x for x in os.listdir(output_dir) if x.split(\".\")[-1]==\"csv\"]\n",
    "    data_name=sorted(data_name)\n",
    "    df=pd.read_csv(os.path.join(output_dir , data_name[0]))\n",
    "    metrics=metrics_read(df,model_name)\n",
    "    for i in range(1,len(data_name)):\n",
    "        df=pd.read_csv(os.path.join(output_dir , data_name[i]))\n",
    "        metrics=pd.concat([metrics,metrics_read(df,model_name)],axis=0,ignore_index=True)\n",
    "        \n",
    "    metrics.drop_duplicates(subset=[\"recall\"],inplace=True, keep=\"first\")\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d27299b-79fb-4be1-b656-6d6a5c3ce92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision=[]\n",
    "recall=[]\n",
    "\n",
    "output_dir=\"/opt/omniai/work/instance1/jupyter/v3_new_email/Fine-Tuning/results/longformer_base_4096\"\n",
    "df=metrics_df(output_dir, \"longformer_base\")\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "output_dir=\"/opt/omniai/work/instance1/jupyter/v3_new_email/Fine-Tuning/results/longformer_base_4096_customized\"\n",
    "df=metrics_df(output_dir, \"longformer_base\")\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "output_dir=\"/opt/omniai/work/instance1/jupyter/v3_new_email/Fine-Tuning/results/longformer_large_4096\"\n",
    "df=metrics_df(output_dir, \"longformer_large\")\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "output_dir=\"/opt/omniai/work/instance1/jupyter/v3_new_email/Fine-Tuning/results/longformer_large_4096_customized\"\n",
    "df=metrics_df(output_dir, \"longformer_large\")\n",
    "precision.append(df[\"precision\"].tolist())\n",
    "recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "# output_dir=\"/opt/omniai/work/instance1/jupyter/v3_new_email/Fine-Tuning/results/bigbird_roberta_large\"\n",
    "# df=metrics_df(output_dir, \"bigbird_large\")\n",
    "# precision.append(df[\"precision\"].tolist())\n",
    "# recall.append(df[\"recall\"].tolist())\n",
    "\n",
    "# output_dir=\"/opt/omniai/work/instance1/jupyter/v3_new_email/Fine-Tuning/results/bigbird_roberta_large_customized\"\n",
    "# df=metrics_df(output_dir, \"bigbird_large\")\n",
    "# precision.append(df[\"precision\"].tolist())\n",
    "# recall.append(df[\"recall\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933d5993-b264-4d9c-9d13-4a4af4686b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "# Define precision and recall values for each model\n",
    "# models = ['longformer-base','customized longformer-base', 'longformer-large','customized longformer-large', 'bigbird-large','customized bigbird-large']\n",
    "models = ['longformer-base','customized longformer-base', 'longformer-large','customized longformer-large']\n",
    "\n",
    "# markers = ['o', 's', 'D', 'x', '*',  'p']\n",
    "# colors = ['blue', 'green', 'orange', 'red', 'purple','black']\n",
    "markers = ['o', 's', 'D', 'x']\n",
    "colors = ['blue', 'green', 'orange', 'red']\n",
    "\n",
    "# Plot precision and recall\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Iterate over models\n",
    "for i in range(len(models)):\n",
    "    plt.plot(recall[i], precision[i], marker=markers[i],  color=colors[i], label=models[i], linewidth=3, linestyle=\":\", markersize=8)\n",
    "\n",
    "plt.xlabel('Recall', fontsize=12)\n",
    "plt.ylabel('Precision', fontsize=12)\n",
    "plt.title('Precision-Recall Curve', fontsize=14)\n",
    "plt.grid(True)\n",
    "\n",
    "# Format axis values as percentages\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=0))\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=2))\n",
    "\n",
    "# Set the legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed38ad5-7259-4e8e-a626-6774249172ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt1",
   "language": "python",
   "name": "pt1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
