{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01f8ecd-ca5f-4d1d-9879-4d8f3b02d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import argparse\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment=None\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas(position=0,leave=True)\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import utils\n",
    "\n",
    "import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "import nltk\n",
    "# from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk_data_dir=os.path.join(\"/opt/omniai/work/instance1/jupyter/\", \"transformers-models\",\"nltk_data\")\n",
    "stopwords_file = open(nltk_data_dir + '/corpora/stopwords/english')\n",
    "stopwords_list = stopwords_file.readlines()\n",
    "STOPWORDS=[x.strip() for x in stopwords_list]\n",
    "nltk.data.path.append(nltk_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2446a67d-7e3d-433b-aa68-b03945f1112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name=\"inference_data_0923\"\n",
    "path_0=\"/opt/omniai/work/instance1/jupyter/v5_new_email/cb-cx-complaints-container/model_monitoring\"\n",
    "email_data=pd.read_pickle(os.path.join(path_0,data_name))\n",
    "test_output_v0=utils.model_evaluate(email_data[\"target\"].values.reshape(-1),email_data.prob_pred.squeeze(),email_data.best_threshold.unique()[0])\n",
    "# test_output_v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dc9b4f-763f-4930-851d-db1e260e2b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name=\"inf_0923_feedback\"\n",
    "dedup_type=\"dedup_target\"\n",
    "path=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/TFIDF_revisit_v1/daily_inference/split_data/pred_output/{dedup_type}/\"\n",
    "email_data=pd.read_pickle(os.path.join(path,data_name))\n",
    "\n",
    "data_name=\"inf_0823_feedback\"\n",
    "path=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/TFIDF_revisit_v1/daily_inference/reference_data/split_data/pred_output/{dedup_type}/\"\n",
    "best_threshold=pd.read_pickle(os.path.join(path,data_name)).best_threshold.unique()[0]\n",
    "# model_dir=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/TFIDF_revisit_v1/features/{dedup_type}/tfidf_model/\"\n",
    "# with open(os.path.join(model_dir,\"best_threshold_val.txt\"),'r') as f:\n",
    "#     best_threshold=float(f.readline())\n",
    "test_output_v1=utils.model_evaluate(email_data[\"target\"].values.reshape(-1),email_data.prob_pred.squeeze(),best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2398b5-b561-4692-a64a-3a1ab6df308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name=\"inf_0923\"\n",
    "model=\"longformer_base_4096\"\n",
    "path=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/Fine-Tuning_v1/daily_inference/split_data/pred_output/{model}/\"\n",
    "email_data=pd.read_pickle(os.path.join(path,data_name))\n",
    "\n",
    "data_name=\"inf_0823\"\n",
    "path=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/Fine-Tuning_v1/daily_inference/reference_data/split_data/pred_output/{model}/\"\n",
    "best_threshold=pd.read_pickle(os.path.join(path,data_name)).best_threshold.unique()[0]\n",
    "\n",
    "email_data.dropna(subset=[\"target\"],axis=0,inplace=True)\n",
    "test_output_v2=utils.model_evaluate(email_data[\"target\"].values.reshape(-1),email_data.Predicted_prob.squeeze(),best_threshold)\n",
    "# test_output_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326a8121-6a54-4882-b421-78841f5bffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b=email_data[\"target\"].value_counts().tolist()\n",
    "precision_lexican=(b/(a+b))\n",
    "    \n",
    "print()\n",
    "print(\"********** precision comparision ***********\")\n",
    "print()\n",
    "print(\"{:<25}{:<20.4%}\".format(\"Lexican Search\",precision_lexican))\n",
    "print(\"{:<25}{:<20.4%}\".format(\"existing TFIDF Model\",test_output_v0[\"precision\"]))\n",
    "print(\"{:<25}{:<20.4%}\".format(\"updated TFIDF Model\",test_output_v1[\"precision\"]))\n",
    "print(\"{:<25}{:<20.4%}\".format(\"longformer-base \",test_output_v2[\"precision\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45447c07-90a1-4bb0-af7b-8b67c3b86b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"********** Recall comparision ***********\")\n",
    "print()\n",
    "print(\"{:<25}{:<20.0%}\".format(\"Lexican Search\",1))\n",
    "print(\"{:<25}{:<20.4%}\".format(\"existing TFIDF Model\",test_output_v0[\"recall\"]))\n",
    "print(\"{:<25}{:<20.4%}\".format(\"updated TFIDF Model\",test_output_v1[\"recall\"]))\n",
    "print(\"{:<25}{:<20.4%}\".format(\"longformer-base \",test_output_v2[\"recall\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fc3489-f0c9-4003-91b8-6216a64fc815",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b=email_data[\"target\"].value_counts().tolist()\n",
    "\n",
    "print()\n",
    "print(\"********** False Positive ***********\")\n",
    "print()\n",
    "print(\"{:<25}{:<20,}\".format(\"Lexican Search\",a))\n",
    "print(\"{:<25}{:<20,}\".format(\"existing TFIDF Model\",test_output_v0[\"false positive\"]))\n",
    "print(\"{:<25}{:<20,}\".format(\"updated TFIDF Model\",test_output_v1[\"false positive\"]))\n",
    "print(\"{:<25}{:<20,}\".format(\"longformer-base \",test_output_v2[\"false positive\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68440ce2-67c3-4683-9ef9-b8ee78380cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"********** False Negative ***********\")\n",
    "print()\n",
    "print(\"{:<20}{:<20,}\".format(\"Lexican Search\",0))\n",
    "print(\"{:<25}{:<20,}\".format(\"existing TFIDF Model\",test_output_v0[\"false_negative\"]))\n",
    "print(\"{:<25}{:<20,}\".format(\"updated TFIDF Model\",test_output_v1[\"false_negative\"]))\n",
    "print(\"{:<25}{:<20,}\".format(\"longformer-base \",test_output_v2[\"false_negative\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d377ca-e0c9-4701-ba30-06ce9f968cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"********** Reduce Lexican Hit Percentage ***********\")\n",
    "print()\n",
    "lexican_hit=a+b\n",
    "x0=test_output_v0['false positive']+int(test_output_v0['total positive']*test_output_v0['recall'])\n",
    "x1=test_output_v1['false positive']+int(test_output_v1['total positive']*test_output_v1['recall'])\n",
    "x2=test_output_v2['false positive']+int(test_output_v2['total positive']*test_output_v2['recall'])\n",
    "\n",
    "print(\"{:<25}{:<20.2%}\".format(\"existing TFIDF Model\", 1-x0/lexican_hit))\n",
    "print(\"{:<25}{:<20.2%}\".format(\"updated TFIDF Model\", 1-x1/lexican_hit))\n",
    "print(\"{:<25}{:<20.2%}\".format(\"longformer-base \",  1-x2/lexican_hit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5344ea-07ed-4571-ad19-d189c022b25e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a3abc9-c767-4e21-8f96-1065c7a69c88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2d563c-2b69-46ae-a635-e5dd4de8f5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name=\"inference_data_0923\"\n",
    "path_0=\"/opt/omniai/work/instance1/jupyter/v5_new_email/cb-cx-complaints-container/model_monitoring\"\n",
    "email_data_v0=pd.read_pickle(os.path.join(path_0,data_name))\n",
    "keep_columns=['snapshot_id', 'gcid', 'time','target','prob_pred','best_threshold']\n",
    "email_data_v0=email_data_v0.loc[:,keep_columns]\n",
    "email_data_v0.rename(columns={'prob_pred':'prob_pred_v0','best_threshold':'best_threshold_v0'},inplace=True)\n",
    "email_data_v0['time'] = pd.to_datetime(email_data_v0['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84483cc7-48b0-47ce-b539-53df76896ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name=\"inf_0923_feedback\"\n",
    "dedup_type=\"dedup_target\"\n",
    "path=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/TFIDF_revisit_v1/daily_inference/split_data/pred_output/{dedup_type}/\"\n",
    "email_data_v1=pd.read_pickle(os.path.join(path,data_name))\n",
    "\n",
    "data_name=\"inf_0823_feedback\"\n",
    "path=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/TFIDF_revisit_v1/daily_inference/reference_data/split_data/pred_output/{dedup_type}/\"\n",
    "best_threshold=pd.read_pickle(os.path.join(path,data_name)).best_threshold.unique()[0]\n",
    "\n",
    "email_data_v1['best_threshold_v1']=best_threshold\n",
    "keep_columns=['snapshot_id', 'gcid', 'time','target','prob_pred','best_threshold_v1']\n",
    "email_data_v1=email_data_v1.loc[:,keep_columns]\n",
    "email_data_v1.rename(columns={'prob_pred':'prob_pred_v1'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0de7fb8-9ec0-444a-8796-2538b58f0b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name=\"inf_0923\"\n",
    "model=\"longformer_base_4096\"\n",
    "path=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/Fine-Tuning_v1/daily_inference/split_data/pred_output/{model}/\"\n",
    "email_data_v2=pd.read_pickle(os.path.join(path,data_name))\n",
    "\n",
    "data_name=\"inf_0823\"\n",
    "path=f\"/opt/omniai/work/instance1/jupyter/v5_new_email/Fine-Tuning_v1/daily_inference/reference_data/split_data/pred_output/{model}/\"\n",
    "best_threshold=pd.read_pickle(os.path.join(path,data_name)).best_threshold.unique()[0]\n",
    "\n",
    "email_data_v2['best_threshold_v2']=best_threshold\n",
    "keep_columns=['snapshot_id', 'gcid', 'time','target','Predicted_prob','best_threshold_v2']\n",
    "email_data_v2=email_data_v2.loc[:,keep_columns]\n",
    "email_data_v2.rename(columns={'Predicted_prob':'prob_pred_v2'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e83cc2-bf90-407c-9b81-4a61e058b50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_data=email_data_v0.merge(email_data_v1, on=['snapshot_id', 'gcid','time','target'],how=\"inner\")\n",
    "email_data=email_data.merge(email_data_v2, on=['snapshot_id', 'gcid','time','target'],how=\"inner\")\n",
    "email_data['year'] = email_data.time.apply(lambda x: x.year)\n",
    "email_data['month'] = email_data.time.apply(lambda x: x.month)\n",
    "email_data['day'] = email_data.time.apply(lambda x: x.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afa93a7-a9dd-4f5f-881f-b7ddbcf13151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_precision_chart(email_data, var=\"target\", subtitle=\"test_set=0901~0930\"):\n",
    "    recall_v0=[]\n",
    "    recall_v1=[]\n",
    "    recall_v2=[]\n",
    "    precision_v0=[]\n",
    "    precision_v1=[]\n",
    "    precision_v2=[]\n",
    "\n",
    "    recall_lexican=[]\n",
    "    precision_lexican=[]\n",
    "\n",
    "    daily_vt=sorted(email_data.day.unique())\n",
    "\n",
    "    for i,t in enumerate(daily_vt):\n",
    "        tempt=email_data[email_data.day==t]    \n",
    "        best_threshold_v0=tempt.best_threshold_v0.unique()[0]\n",
    "        best_threshold_v1=tempt.best_threshold_v1.unique()[0]\n",
    "        best_threshold_v2=tempt.best_threshold_v2.unique()[0]\n",
    "\n",
    "        recall_lexican.append(1)\n",
    "\n",
    "        if tempt[tempt[var]==1].shape[0]!=0:\n",
    "            a, b=tempt[var].value_counts().tolist()\n",
    "            precision_lexican.append(b/(a+b))\n",
    "\n",
    "            test_output_v0=utils.model_evaluate(tempt[var].values.reshape(-1),tempt.prob_pred_v0.squeeze(),best_threshold_v0)\n",
    "            recall_v0.append(test_output_v0[\"recall\"])\n",
    "            precision_v0.append(test_output_v0[\"precision\"])\n",
    "\n",
    "            test_output_v1=utils.model_evaluate(tempt[var].values.reshape(-1),tempt.prob_pred_v1.squeeze(),best_threshold_v1)\n",
    "            recall_v1.append(test_output_v1[\"recall\"])\n",
    "            precision_v1.append(test_output_v1[\"precision\"])\n",
    "\n",
    "            test_output_v2=utils.model_evaluate(tempt[var].values.reshape(-1),tempt.prob_pred_v2.squeeze(),best_threshold_v2)\n",
    "            recall_v2.append(test_output_v2[\"recall\"])\n",
    "            precision_v2.append(test_output_v2[\"precision\"])\n",
    "\n",
    "        else:\n",
    "            recall_v0.append(1)\n",
    "            recall_v1.append(1)\n",
    "            recall_v2.append(1)\n",
    "            precision_v0.append(0)\n",
    "            precision_v1.append(0)\n",
    "            precision_v2.append(0)\n",
    "            precision_lexican.append(0)\n",
    "            \n",
    "    # models = ['Lexican_search','TFIDF_lightgbm_v0','TFIDF_lightgbm_v1','TFIDF_lightgbm_v2']\n",
    "    # markers = ['o', 's','x','D']\n",
    "    # colors = ['blue','red','green', 'purple']\n",
    "    \n",
    "    models = ['Lexican_search','Existing TFIDF Model','Updated TFIDF Model','Language Model']\n",
    "    markers = ['o', 's','x','D']\n",
    "    colors = ['blue','red','green', 'purple']\n",
    "    \n",
    "    # Plot precision and recall\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    plt.plot(daily_vt, precision_lexican, marker=markers[0],  color=colors[0], label=models[0], linewidth=3, linestyle=\":\", markersize=8)\n",
    "    plt.plot(daily_vt, precision_v0, marker=markers[1],  color=colors[1], label=\"Existing TFIDF Model\", linewidth=3, linestyle=\":\", markersize=8)\n",
    "    plt.plot(daily_vt, precision_v1, marker=markers[2],  color=colors[2], label=\"Updated TFIDF Model\", linewidth=3, linestyle=\":\", markersize=8)\n",
    "    plt.plot(daily_vt, precision_v2, marker=markers[3],  color=colors[3], label=\"Language Model\", linewidth=3, linestyle=\":\", markersize=8)\n",
    "\n",
    "    plt.xlabel('Day', fontsize=14)\n",
    "    plt.ylabel('Precision', fontsize=14)\n",
    "    plt.title(f'Daily Precision \\n({subtitle})', fontsize=16)\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Format axis values as percentages\n",
    "    ax = plt.gca()\n",
    "    ax.yaxis.set_major_locator(mtick.MultipleLocator(base=0.001))\n",
    "    ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=2))\n",
    "\n",
    "    # plt.ylim(0.006,0.03)\n",
    "    # plt.xlim(0.96,1.001)\n",
    "\n",
    "    plt.xticks(daily_vt)\n",
    "    plt.xticks(rotation=90)\n",
    "    # Set the legend\n",
    "    plt.legend(loc='upper right', fontsize=16)\n",
    "    plt.show()\n",
    "    \n",
    "    models = ['Lexican_search','Existing TFIDF Model','Updated TFIDF Model','Language Model']\n",
    "    markers = ['o', 's','x','D']\n",
    "    colors = ['blue','red','green', 'purple']\n",
    "\n",
    "    # Plot precision and recall\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    plt.plot(daily_vt, recall_lexican, marker=markers[0],  color=colors[0], label=models[0], linewidth=3, linestyle=\":\", markersize=8)\n",
    "    plt.plot(daily_vt, recall_v0, marker=markers[1],  color=colors[1], label=\"Existing TFIDF Model\", linewidth=3, linestyle=\":\", markersize=8)\n",
    "    plt.plot(daily_vt, recall_v1, marker=markers[2],  color=colors[2], label=\"Updated TFIDF Model\", linewidth=3, linestyle=\":\", markersize=8)\n",
    "    plt.plot(daily_vt, recall_v2, marker=markers[3],  color=colors[3], label=\"Language Model\", linewidth=3, linestyle=\":\", markersize=8)\n",
    "\n",
    "    plt.xlabel('Day', fontsize=14)\n",
    "    plt.ylabel('Recall', fontsize=14)\n",
    "    plt.title(f'Daily Recall \\n({subtitle})', fontsize=16)\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Format axis values as percentages\n",
    "    ax = plt.gca()\n",
    "    ax.yaxis.set_major_locator(mtick.MultipleLocator(base=0.05))\n",
    "    ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=2))\n",
    "\n",
    "    plt.xticks(daily_vt)\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "    # Set the legend\n",
    "    plt.legend(loc='lower right', fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3939a9-c708-41b4-b2bd-9dbf5dd63586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def false_psoitive_negative_chart(email_data, var=\"target\", subtitle=\"test_set=0901~0930\"):\n",
    "    false_negative_v0=[]\n",
    "    false_negative_v1=[]\n",
    "    false_negative_v2=[]\n",
    "    false_positive_v0=[]\n",
    "    false_positive_v1=[]\n",
    "    false_positive_v2=[]\n",
    "\n",
    "    false_positive_lexican=[]\n",
    "    daily_vt=sorted(email_data.day.unique())\n",
    "\n",
    "    for i,t in enumerate(daily_vt):\n",
    "        tempt=email_data[email_data.day==t]    \n",
    "        best_threshold_v0=tempt.best_threshold_v0.unique()[0]\n",
    "        best_threshold_v1=tempt.best_threshold_v1.unique()[0]\n",
    "        best_threshold_v2=tempt.best_threshold_v2.unique()[0]    \n",
    "\n",
    "        if tempt[tempt[var]==1].shape[0]!=0:\n",
    "            a, b=tempt[var].value_counts().tolist()    \n",
    "            false_positive_lexican.append(a)\n",
    "            test_output_v0=utils.model_evaluate(tempt[var].values.reshape(-1),tempt.prob_pred_v0.squeeze(),best_threshold_v0)\n",
    "            false_positive_v0.append(test_output_v0[\"false positive\"])\n",
    "            false_negative_v0.append(test_output_v0[\"false_negative\"])\n",
    "\n",
    "            test_output_v1=utils.model_evaluate(tempt[var].values.reshape(-1),tempt.prob_pred_v1.squeeze(),best_threshold_v1)\n",
    "            false_positive_v1.append(test_output_v1[\"false positive\"])\n",
    "            false_negative_v1.append(test_output_v1[\"false_negative\"])\n",
    "\n",
    "            test_output_v2=utils.model_evaluate(tempt[var].values.reshape(-1),tempt.prob_pred_v2.squeeze(),best_threshold_v2)\n",
    "            false_positive_v2.append(test_output_v2[\"false positive\"])\n",
    "            false_negative_v2.append(test_output_v2[\"false_negative\"])\n",
    "\n",
    "        else:\n",
    "            false_positive_lexican.append(0)\n",
    "\n",
    "            false_negative_v0.append(0)\n",
    "            false_positive_v0.append(0)\n",
    "\n",
    "            false_negative_v1.append(0)\n",
    "            false_positive_v1.append(0)\n",
    "\n",
    "            false_negative_v2.append(0)\n",
    "            false_positive_v2.append(0)\n",
    "            \n",
    "    bar_width=0.25\n",
    "    spacing=1.5\n",
    "    \n",
    "    index=np.arange(0, len(daily_vt)*spacing,spacing)\n",
    "    plt.figure(figsize=(15, 8))\n",
    "\n",
    "    bar0=plt.bar(index, false_positive_lexican, bar_width,  label=\"Lexican_search\", color=\"blue\", edgecolor=\"black\")\n",
    "    bar1=plt.bar(index+bar_width, false_positive_v0, bar_width,  label=\"Existing TFIDF Model\", color=\"red\", edgecolor=\"black\")\n",
    "    bar2=plt.bar(index+2*bar_width, false_positive_v1, bar_width,  label=\"Updated TFIDF Model\", color=\"green\", edgecolor=\"black\")\n",
    "    bar3=plt.bar(index+3*bar_width, false_positive_v2, bar_width,  label=\"Language Model\", color=\"purple\", edgecolor=\"black\")\n",
    "\n",
    "    plt.xlabel('Day', fontsize=14)\n",
    "    plt.ylabel('Number of False Positive', fontsize=14)\n",
    "    plt.title(f'Daily False Positive \\n({subtitle})', fontsize=16)\n",
    "    plt.grid(axis=\"y\")\n",
    "\n",
    "    plt.xticks(index+bar_width,daily_vt)\n",
    "    plt.xticks(rotation=90)\n",
    "    # plt.ylim(0.006,0.03)\n",
    "    # Set the legend\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    bar_width=0.25\n",
    "    spacing=1.5\n",
    "    index=np.arange(0, len(daily_vt)*spacing,spacing)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "\n",
    "    bar1=plt.bar(index, false_negative_v0, bar_width,  label=\"Existing TFIDF Model\", color=\"red\", edgecolor=\"black\")\n",
    "    bar2=plt.bar(index+bar_width, false_negative_v1, bar_width,  label=\"Updated TFIDF Model\", color=\"green\", edgecolor=\"black\")\n",
    "    bar3=plt.bar(index+2*bar_width, false_negative_v2, bar_width,  label=\"Language Model\", color=\"purple\", edgecolor=\"black\")\n",
    "\n",
    "    plt.xlabel('Day', fontsize=14)\n",
    "    plt.ylabel('Number of False Negative', fontsize=14)\n",
    "    plt.title(f'Daily False Negative \\n({subtitle})', fontsize=16)\n",
    "    plt.grid(axis=\"y\")\n",
    "\n",
    "    plt.xticks(index+bar_width,daily_vt)\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "    plt.yticks([0,1,2])\n",
    "    plt.ylim(0,2)\n",
    "    # Set the legend\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e852d8-2fdf-41bf-a92c-a36e158d006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_precision_chart(email_data, var=\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11750ff-e569-4e41-8acf-250caafed5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_psoitive_negative_chart(email_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec9310c-9691-4564-b615-54e7f3f759db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def false_psoitive_reduction(email_data, var=\"target\"):\n",
    "    false_negative_v0=[]\n",
    "    # false_negative_v1=[]\n",
    "    # false_negative_v2=[]\n",
    "    false_positive_v0=[]\n",
    "    # false_positive_v1=[]\n",
    "    # false_positive_v2=[]\n",
    "\n",
    "    false_positive_lexican=[]\n",
    "    daily_vt=sorted(email_data.day.unique())\n",
    "\n",
    "    for i,t in enumerate(daily_vt):\n",
    "        tempt=email_data[email_data.day==t]    \n",
    "        best_threshold_v0=tempt.best_threshold_v0.unique()[0]\n",
    "        # best_threshold_v1=tempt.best_threshold_v1.unique()[0]\n",
    "        # best_threshold_v2=tempt.best_threshold_v2.unique()[0]    \n",
    "\n",
    "        if tempt[tempt[var]==1].shape[0]!=0:\n",
    "            a, b=tempt[var].value_counts().tolist()    \n",
    "            false_positive_lexican.append(a)\n",
    "            test_output_v0=utils.model_evaluate(tempt[var].values.reshape(-1),tempt.prob_pred_v0.squeeze(),best_threshold_v0)\n",
    "            false_positive_v0.append(test_output_v0[\"false positive\"])\n",
    "            false_negative_v0.append(test_output_v0[\"false_negative\"])\n",
    "\n",
    "#             test_output_v1=utils.model_evaluate(tempt[var].values.reshape(-1),tempt.prob_pred_v1.squeeze(),best_threshold_v1)\n",
    "#             false_positive_v1.append(test_output_v1[\"false positive\"])\n",
    "#             false_negative_v1.append(test_output_v1[\"false_negative\"])\n",
    "\n",
    "#             test_output_v2=utils.model_evaluate(tempt[var].values.reshape(-1),tempt.prob_pred_v2.squeeze(),best_threshold_v2)\n",
    "#             false_positive_v2.append(test_output_v2[\"false positive\"])\n",
    "#             false_negative_v2.append(test_output_v2[\"false_negative\"])\n",
    "\n",
    "        else:\n",
    "            false_positive_lexican.append(0)\n",
    "\n",
    "            false_negative_v0.append(0)\n",
    "            false_positive_v0.append(0)\n",
    "\n",
    "#             false_negative_v1.append(0)\n",
    "#             false_positive_v1.append(0)\n",
    "\n",
    "#             false_negative_v2.append(0)\n",
    "#             false_positive_v2.append(0)\n",
    "            \n",
    "\n",
    "    bar_width=0.45\n",
    "    spacing=1.5\n",
    "    \n",
    "    index=np.arange(0, len(daily_vt)*spacing,spacing)\n",
    "    plt.figure(figsize=(15, 8))\n",
    "\n",
    "    bar0=plt.bar(index, false_positive_lexican, bar_width,  label=\"Lexican_search\", color=\"blue\", edgecolor=\"black\")\n",
    "    bar1=plt.bar(index+bar_width, false_positive_v0, bar_width,  label=\"TFIDF Model\", color=\"red\", edgecolor=\"black\")\n",
    "\n",
    "    # Annotate with the percentage reduction\n",
    "    for i, (v0, v1) in enumerate(zip(false_positive_lexican, false_positive_v0)):\n",
    "        if v0!=0:\n",
    "            reduction = ((v0 - v1) / v0) * 100\n",
    "            plt.annotate(f'-{reduction:.1f}%', \n",
    "                         (index[i] + bar_width, v1 + 2), \n",
    "                         ha='center', va='bottom', \n",
    "                         fontsize=10, \n",
    "                         color='black')\n",
    "\n",
    "\n",
    "    plt.xlabel('Day', fontsize=14)\n",
    "    plt.ylabel('Number of False Positive', fontsize=14)\n",
    "    plt.title('Daily False Positive \\n(test_set=0901~0930)', fontsize=16)\n",
    "    plt.grid(axis=\"y\")\n",
    "\n",
    "    plt.xticks(index+bar_width,daily_vt)\n",
    "    plt.xticks(rotation=90)\n",
    "    # plt.ylim(0.006,0.03)\n",
    "    # Set the legend\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecd2dce-12b2-4fdf-a459-97376253ac01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db72d765-c15e-40eb-9859-d92d1303d7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f578e2-9174-43e4-a799-8fd75f7e2e70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2781b103-d42f-458d-bf3f-83310232722f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d7a44f-b358-47f1-bd2a-fa5dc39c0d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e3146b-10e2-40cf-aeb3-a319c81cf64b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d340db2b-2de2-4d79-822f-338594c0736f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
